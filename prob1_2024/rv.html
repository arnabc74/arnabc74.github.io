<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta content="text/html;charset=UTF-8" http-equiv="Content-Type"/>
<link rel="stylesheet" type="text/css" href="../tools/ctut.css"/>
<link type="text/css" rel="stylesheet" href="../tools/style.css"/>
<style type="text/css">@font-face {font-family: SHREE_BAN_OTF_0592;src: local("../tools/SHREE_BAN_OTF_0592"),url(../tools/SHREE-BAN-OTF-new.woff) format("opentype");</style>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<div id="fb-root"></div>
<script async defer crossorigin="anonymous" src="https://connect.facebook.net/en_US/sdk.js#xfbml=1&version=v19.0" nonce="Q7jTbrCq"></script>

<script src="../tools/jquery-1.10.2.min.js"></script>

<script>
aha = function(code) {
  window.open("https://rdrr.io/snippets/embed/?code="+code)
}

togglePhoto = function(photoId) {
   var me = document.getElementById("pic_"+photoId)
   if(me.style.display=="block"){
     me.style.display="none";
   }
   else if (me.style.display=="none"){
     me.style.display="block";
   }
}

hideShow = function(lb) {
   var me = document.getElementById(lb)
   if(me.style.display=="block"){
     me.style.display="none";
   }
   else {
     me.style.display="block";
   }
}

grabData = function(data){
  return "https://farm"+data.photo.farm+".staticflickr.com/"+data.photo.server+"/"+data.photo.id+"_"+
            data.photo.secret+".jpg"
}

fromFlickr = function(photoId) {

$.getJSON("https://api.flickr.com/services/rest/?method=flickr.photos.getInfo&api_key=23a138c73bdbe1e68601aa7866924e62&user_id=109924623@N07&photo_id="+photoId+"&lang=en-us&format=json&jsoncallback=?",
  function(data) {
    imgURL = grabData(data)
    var l = document.getElementById("lnk_"+photoId)
    l.href = "https://www.flickr.com/photos/109924623@N07/"+photoId
    var i = document.getElementById("pic_"+photoId)
    i.src=imgURL
    i.onload = function() {
      document.getElementById("status_"+photoId).innerHTML="[Image loaded. Click to show/hide.]"
    }
  })
}
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js","color.js"],
    jax: ["input/TeX","output/HTML-CSS"],
    tex2jax: {inlineMath: [["$","$"],["\\(","\\)"]]},
    TeX: {
      Macros: {
        h: ["{\\hat #1}",1],
        b: ["{\\overline #1}", 1],
        row: "{\\mathcal R}",
        col: "{\\mathcal C}",
        nul: "{\\mathcal N}"
      }
    }
  });
</script>
<style>
body,table {
  margin: 0;
  font-size: 40;
  //background: #000;
  //color: #fff;
}

.ans {
  display:none;
  background: #ccffcc;
}

.sticky {
  position: fixed;
  top: 0;
  width: 100%;
  background: #555;
  color: #f1f1f1;
}

.cu {
  background: #ffcccc;
}

.bu {
  background: #ccccff;
}

.scrpt {
  margin:10px;
  border-left: 5px solid black;
}

.box {
  border: 2px solid black;
  display: inline-block;
}
</style>
<script>
window.onscroll = function() {myFunction()};
window.onload = function() {myInit()};

var header, tphldr;
function myInit() {
  header = document.getElementsByClassName("header");
  tphldr = document.getElementById("topholder");
}

function myFunction() {
  var index = -1
  for(i=0;i<header.length;i++) {
    if (window.pageYOffset > header[i].offsetTop) {
       index = i
    }
    else {
       break
    }
  }

  if(index < 0) 
    tphldr.innerHTML = "";
  else
    tphldr.innerHTML = header[index].innerHTML
}
</script><script type="text/javascript" src="https://arnabc74.github.io/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type="text/javascript" src="file:///home/asu/na/v/MathJax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="../tools/htmlwidgets.js"></script>
<link href="../tools/rgl.css" rel="stylesheet"></link>
<script src="../tools/rglClass.src.js"></script>
<script src="../tools/CanvasMatrix.src.js"></script>
<script src="../tools/rglWebGL.js"></script>
</head><body>
<div class="sticky" id="topholder"> </div>
<a href="http://www.isical.ac.in/~arnabc/">[Home]</a>
<h3>Table of contents</h3>
<ul>
<li>
<a href="#Random variables">Random variables</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#What they are">What they are</a>
</li>
<li>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
<a href="#A little measure theory again">A little measure theory again</a>
</li>
<li>
<a href="#New random variables from old ones">New random variables from old ones</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Addition, multiplication etc">Addition, multiplication etc</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Functions of a random variable">Functions of a random variable</a>
</li>
<li>
<a href="#Distribution of a random variable">Distribution of a random variable</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#CDF">CDF</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Different types of random variables">Different types of random variables</a>
</li>
<li>
<a href="#PMF">PMF</a>
</li>
<li>
<a href="#Expectation of a random variable">Expectation of a random variable</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Finite case">Finite case</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Nonnegative case">Nonnegative case</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#General case">General case</a>
</li>
<li>
<a href="#How to compute expectation easily?">How to compute expectation easily?</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Random variables taking countably many values">Random variables taking countably many values</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Expectation of a function">Expectation of a function</a>
</li>
<li>
<a href="#Properties of expectation">Properties of expectation</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Relation of $E(X)$ with values of $X$">Relation of $E(X)$ with values of $X$</a>
</li>
<li>&nbsp;&nbsp;&nbsp;
<a href="#Transformation properties">Transformation properties</a>
</li>
<li>
<a href="#Indicator trick">Indicator trick</a>
</li>
<li>
<a href="#Problems for practice">Problems for practice</a>
</li>
</ul>
<hr/>

<h1><a
name="Random variables">Random variables</a></h1>

<h2><a
name="What they are">What they are</a></h2>
Suppose that I toss a fair coin, and offer you Rs 10 for a head,
and demand $Rs 20$ for a tail. In other words, your gain (in Rs)
from this deal is $10$ for head and $-20$ for
tail. Both $10$ and $-20$ are constants, but since you
do not know which of these two constants you are going to get,
you gain is a variable. Since it varies with chance, we call it
a <b>random variable</b>.
<p></p>
Think of this as made of two stages. In the first stage we have a random
 experiment with $\Omega = $
 {Head, Tail}. In the second stage we have a function
 $X:\Omega\rightarrow {\mathbb R}$
defined as 
$$\begin{eqnarray*}
X(head) &amp; = &amp; 10,\\
X(tail) &amp; = &amp; -20.
\end{eqnarray*}$$
There is nothing random about this <i>function</i>. The randomness comes
from the mechanism that decides what goes <i>into</i> this: head or tail?
<p></p>
We use this idea to define random variables mathematically. We
start with a random experiment which is the provider of the
randomness. Then any (real valued) function defined on its sample space is
called a random variable. In probability theory, it is the function
(which is not at all random) that is called the random
variable. Thus, if in the above coin toss example, we replace the
fair coin with a biased coin, but keep the payment rules the
same, then we still have the same random variable. 
<p></p>
Beginners often find it odd: a random variable is neither random
nor a variable!
<p></p>
However, it is not as unnatural as it sounds. In calculus also we
write $y = x^2$ and say $y$ is a variable as well
as $y$ is a function of $x.$
<p></p>

<p>
<b>EXAMPLE 1:</b>&nbsp;
In the coin tossing example with a fair coin, let your gain be
denoted by $X.$ (or sometimes $X(w)$, if you want to emphasize
that it is a function).  Find $P(X=10).$
<p></p>
<b>SOLUTION:</b>
The immediate answer is $\frac 12.$ Let's see the steps that led
to this answer. $P(X=10)$ is the probability that $X$
is $10,$ <i>i.e.</i>, the probability that the coin toss has
produced an outcome for which the function $X$ takes the
value $10.$ Thus 
$$
P(X=10) = P\big\{w\in\{head,tail\}~:~X(w)=10\big\}.
$$
Now $\big\{w\in\{head,tail\}~:~X(w)=10\big\} = \{head\},$ and so
the problem now reduces to finding $P(\{head\}),$ which is $\frac 12.$
 ■
</p>

<p></p>
The general case, then, looks like this: We have a random
experiment with sample space $\Omega.$ A random
variable $X$ is a function $X:\Omega\rightarrow {\mathbb R}$
where ${\mathbb R}$ is any codomain of our choice. If some one gives
us some $A\subseteq {\mathbb R}$ and asks us to find $P(X\in A),$ we
are to actually find 
$$
P\big(\big\{w\in\Omega~:~X(w)\in A\big\}\big).
$$
Remember that this is the <i>definition</i> of $P(X\in A).$
The complicated looking set $\big\{w\in\Omega~:~X(w)\in A\big\}$ is
often abbreviated to $\{X\in A\}$ or $X ^{-1} (A).$
<p></p>

<h3><a
name="A little measure theory again">A little measure theory again</a></h3>
Earlier we had
talked about "good" sets and "bad" sets. The "good" sets constitute a $\sigma$-algebra. 
<p></p>
What if someone asks us
to find $P(X\in A),$ where $X ^{-1} (A)$ is a "bad"
subset of $\Omega?$ Well, the answer is: We shall
simply refuse to find $P(X\in A)$ for such an $A.$ We shall
call such an $A$ a "bad" subset of $S$
(w.r.t. this $X$). A subset $A\subseteq S$ is "good" or
"bad" according as $X ^{-1} (A)$ is "good" or "bad" in $\Omega.$
<p></p>
Now intervals are very useful  subsets of ${\mathbb R}.$ It would be a pity if an interval turns out to be a "bad" subset.
So we work with only those $X:\Omega\rightarrow{\mathbb R}$  where for all intervals $A$ , the set $X^{-1}(A)$  is a
 good subset of $\Omega.$   Such functions $X$  are called <b><font color="red" size="40">Borel measurable</font></b>. 
<p></p>

<fieldset>
<legend><b>Definition: Random variable</b></legend>
Let $\Omega$ be a  non-empty set equipped with a $\sigma$-algebra $ {\mathcal F}.$ 
 Then by a <b><font color="red" size="40">random variable</font></b>  we understand a map $X:\Omega\rightarrow{\mathbb R}$  such that for
 all intervals $A\subseteq{\mathbb R}$  we have $X^{-1}(A)\in{\mathcal F}.$ 
</fieldset>

<p></p>

<h1><a
name="New random variables from old ones">New random variables from old ones</a></h1>

<h2><a
name="Addition, multiplication etc">Addition, multiplication etc</a></h2>
Sometimes we need to combine the values of two or more random
variables. Say $X,Y$ are both random variables and we want
to compute $X+Y.$ Since random variables are actually
functions, so this sum can be formed only when $X$
and $Y$ have the same domain. This simple point sometimes
needs careful handling as the following example shows.
<p></p>

<p>
<b>EXAMPLE 2:</b>&nbsp;
I am playing against two gamblers simultaneosly. One gambler
tosses a fair coin and pays Rs 10 for a head and  takes Rs 20 for  a
tail. The other gambler takes Rs 3 from me, rolls a fair die and pays me as many
rupees as the outcome. What is my total gain? 
<p></p>
<b>SOLUTION:</b>
If I call the gain
from the first gambler $X,$ then $X$ is a function
from $\{head,tail\}$ to ${\mathbb R},$ while the gain from the
second gambler is a function $Y:\{1,2,3,4,5,6\}\rightarrow{\mathbb R}.$
Obviously, $X+Y$ does not make any sense here. We need to
first combine the two random experiments to get the product
sample space: $\{head,tail\}\times\{1,2,3,4,5,6\}$ and then
consider $X,Y$ both as functions from $\Omega$
to ${\mathbb R}.$ For example, $X(head,4) = 10$
and $Y(head,4) = 4-3 = 1.$
<p></p>
Now it is meaningful to talk about $X+Y.$
 ■
</p>

<h2><a
name="Functions of a random variable">Functions of a random variable</a></h2> 
Is any function of a random variable is again a random
variable? Well, for all practical purposes the answer is "yes".  But technically speaking, we have to 
avoid the "bad" subsets. This is how we do it.
<p></p>
Let $X:\Omega\rightarrow{\mathbb R}$  be any random variable. Let $f:{\mathbb R}\rightarrow{\mathbb R}$  be any Borel-mesurable function, <i>i.e.</i>, if $B\in {\mathcal B}$ 
 then $f^{-1}(B)\in {\mathcal B}.$  Then $f(X)$  is again a random variable. Remember that $f(X)$  actually
 means the composition function $(f\circ X):\Omega\rightarrow{\mathbb R}.$
<p></p>

<h1><a
name="Distribution of a random variable">Distribution of a random variable</a></h1>
Consider another gambling game. 
<p>
<b>EXAMPLE 3:</b>&nbsp;
A fair die is rolled. I shall pay you Rs 10 if the die shows an
even number, you'll pay me Rs 20 otherwise. Let's denote
by $Y$ your gain (in Rs). Express $Y$ as a function from $\{1,2,3,4,5,6\}$  to ${\mathbb R}.$
Let $A = \{10\}.$ Find $Y ^{-1} (A)$ and using it
find $P(Y\in A).$ 
<p></p>
<b>SOLUTION:</b>
Here $Y^{-1}(A) = \{2,4,6\}.$ So $P(Y=10) = P(\{2,4,6\}) = \frac 16+\frac 16+\frac 16 = \frac 12.$
 ■
</p>

<p></p>
In each of  these examples we had a random variable  that
took only two values $10$ and $-20.$ Which random variable do
you think is more profitable for you, $X$  or $Y$? Well, both are actually the
same so far as profit goes. Understand this carefully: $X$  and $Y$
 are completely different as functions (their
domains are also different), but in terms of the "behaviour of the
output" of the functions they are identical. This "behaviour of the output" is
called the <b><font color="red" size="40">distribution</font></b> of the random variable. It is the
distribution which we care about mostly in real applications. So
we often start a discussion as 
<blockquote>
Let $X$ be a random variable taking values $10$
and $-20$ each with probability $\frac 12.$
</blockquote>
We understand implicitly that there is <i>some</i> random experiment (say
the coin toss experiment or the die roll experiment or something
similar) and <i>some</i> function from its sample space
to ${\mathbb R}$ such that the distribution is as
specified. In this
course, we shall often omit  the sample space or
the function.
<p></p>

<fieldset>
<legend><b>Definition: Distribution of a random variable</b></legend>
By the <b><font color="red" size="40">distribution</font></b> of a random variable $X$  we mean any statement that gives us $P(X\in B)$  for
 any "good" set $B\subseteq{\mathbb R}.$  
</fieldset>

<p></p>
How do we specify the distribution of a random variable? Do we make a list of all the "good" sets, and label them with
their probabilities? That would woul be insane, because there are uncountaly infinitely many "good" sets. 
It turns out that specifying the probabilities of intervals like $(-\infty, a]$  is enough.
 This is what we discuss next.  
<h2><a
name="CDF">CDF</a></h2>

<fieldset>
<legend><b>Definition: </b></legend>
Let $X$ be any real valued random variable. Then
its <b>(cumulative) distribution function (CDF)</b> is defined as
the function $F:{\mathbb R}\rightarrow[0,1]$ where $\forall x\in{\mathbb R}~~F(x) = P(X\leq x).$
</fieldset>

<p></p>

<p>
<b>EXAMPLE 4:</b>&nbsp;Consider the gambling game that tosses a coin, and has payoffs $-10$  for head, and
 $20$  for tail. Let $X$  denote the payoff. What is its CDF?
<p></p>
<b>SOLUTION:</b>
Here $X$  takes only two values $-10$  and 20, each with probability $\frac 12.$  
<p></p>
So  $F(a) = P(X\leq a) = 0$  whenever $a&lt;-10.$  
<p></p>
But $F(-10)=P(X\leq -10) = \frac 12.$  Indeed, as long as $a\in[-10,20)$  we have $F(a) = \frac 12.$ 
<p></p>
At $a=20,$  we have $F(a) = 1.$  In fact, $\forall a\geq 20~~F(a) = 1.$  So the graph looks like this:
<center>
<table width="100%">
<tr>
<th><img width="" src="image/cdfexm.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center> 
 ■
</p>
The following properties of a CDF are more or less obvious. 
<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let $F(x)$ be the CDF of some rv $X.$ Then 
<ol type="">

<li>$F(x)$ must be nondecreasing, <i>i.e.</i>, $\forall x &lt; y\in{\mathbb R}~F(x)\leq F(y).$</li>

<li>$\lim_{x\rightarrow-\infty} F(x) = 0.$</li>

<li>$\lim_{x\rightarrow\infty} F(x) = 1.$</li>

<li>$F(x)$ must be right continuous, <i>i.e.</i>,
$\forall a\in{\mathbb R}~~F(a+)=F(a).$
 </li>

</ol>

</fieldset>

<p>
<b><i>Proof:</i></b>

<ol type="">

<li>Since $\{X\leq x\} \subseteq \{X\leq y\},$ hence $P(\{X\leq
x\}) \leq P(\{X\leq y\}),$ <i>i.e.</i>, $F(x)\leq F(y).$</li>

<p></p>

<li>
Shall show 
$$
\forall \epsilon&gt;0 ~~ \exists M \in{\mathbb R} ~~ \forall x &lt; M~~ |F(x)-0| &lt; \epsilon.
$$
(Actually we may drop the absolute value sign around $F(x)$
since it is anyway $\geq 0$).
<p></p>

<p></p>

<p></p>
Take any $\epsilon&gt;0.$
<p></p>

<p></p>

<p></p>
Let $A_n$ be the event that $\{X \leq -n\}$
for $n\in{\mathbb N}.$ Then $F(-n) = P(A_n).$
Clearly, $A_1\supseteq A_2\supseteq A_3\supseteq\cdots$
and $\cap A_n=\phi.$
<p></p>
So $P(A_n)\rightarrow 0,$ <i>i.e.</i>, $F(-n)\rightarrow 0.$
<p></p>
So $N\in{\mathbb N} ~~F(-N)&lt;\epsilon.$ 
<p></p>
Choose $M = -N.$
<p></p>
Take any $x &lt; M.$
<p></p>
Then $0\leq F(x) \leq F(M)&lt;\epsilon,$ since $F(\cdot)$ is nondecreasing.
<p></p>
So $|F(x)-0| &lt; \epsilon,$ as required.
</li> 

<li>

<a href="javascript:hideShow('sim');">Very similar. Try yourself first, before clicking here.</a>
<div id="sim" style="display:none;background-color:#ffcccc;">Shall show 
$$
\forall \epsilon&gt;0 ~~ \exists M \in{\mathbb R} ~~ \forall x &gt; M~~ |F(x)-1| &lt; \epsilon.
$$
(Actually we may drop the absolute value sign
around $|F(x)-1|$ is $1-F(x)$,
since $F(x)\leq 1,$ anyway.)
<p></p>

<p></p>
Take any $\epsilon&gt;0.$
<p></p>

<p></p>

<p></p>
Let $A_n$ be the event that $\{X \leq n\}$
for $n\in{\mathbb N}.$ Then $P(A_n)=F(n).$
<p></p>

<p></p>
Clearly, $A_1\subseteq A_2\subseteq A_3\subseteq\cdots$
and $\cup A_n=\Omega.$
<p></p>
So $P(A_n)\rightarrow 1,$ <i>i.e.</i>, $F(n)\rightarrow1.$ 
<p></p>
So $N\in{\mathbb N} ~~|F(N)-1|&lt;\epsilon.$ 
<p></p>
Choose $M = N.$
<p></p>
Take any $x &gt; M.$
<p></p>
Then $0\leq 1-F(x) \leq 1-F(M) &lt;\epsilon,$ since $F(\cdot)$ is nondecreasing.
<p></p>
So $|F(x)-1| &lt; \epsilon,$ as required.
</div>
</li>

<p></p>

<li>
Shall show:
$$
\forall a\in{\mathbb R}~~\forall \epsilon&gt;0~~\exists \delta&gt;0~~ \forall
x\in (a,a+\delta)~~|F(x)-F(a)| &lt; \epsilon.
$$
Take any $a\in{\mathbb R}$ and any $\epsilon&gt;0.$
<p></p>
Let $A_n$ be the event that $\left\{X\leq a+\frac 1n\right\}$ for $n\in{\mathbb N}.$
<p></p>
Also let $A$ be the event that $\{X\leq a\}.$
<p></p>
Then $A_1\supseteq A_2\supseteq\cdots$ and $\cap A_n = A.$
<p></p>
So $P(A_n)\rightarrow P(A)$ and hence $F\left(a+\frac 1n\right)\rightarrow F(a).$
<p></p>
Hence $\exists N\in{\mathbb N} ~~ |F\left(a+\frac 1N\right)-F(a)|&lt;\epsilon.$
<p></p>
Choose $\delta = \frac 1N&gt;0.$
<p></p>
Take any $x\in (a,a+\delta).$
<p></p>
Since $F(\cdot)$ is nondecreasing, hence $F(a)\leq F(x)
\leq F(a+\delta) &lt; F(a)+ \epsilon.$
<p></p>
So $|F(a+x)-F(a)|&lt;\epsilon,$ as required.
</li>

</ol>

<b><i>[QED]</i></b>
</p>

<p></p>
A rather nontrivial  theorem is that the converse is also
true. This converse is called the <b>fundamental theorem of
probability</b>.
<p></p>

<fieldset>
<legend><b><i>Fundamental theorem of probability</i></b></legend>
Let $F:{\mathbb R}\rightarrow[0,1]$ be any function satisfying the
properties listed in the last theorem. Then there must exist a real-valued
rv $X$ with this $F(x)$ as its CDF.
</fieldset>

<p>
<b><i>Proof:</i></b>Too technical for this course.<b><i>[QED]</i></b>
</p>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Any nondecreasing function bounded from above (and hence all
CDF's) must have finite
left hand limit at each point.
</fieldset>

<p>
<b><i>Proof:</i></b>
Let $F:{\mathbb R}\rightarrow{\mathbb R}$ be nondecreasing and bounded from above.
<p></p>
Take any $a\in {\mathbb R}.$
<p></p>
We shall show that $\lim_{x\rightarrow a-} F(x)$ exists as a finite
number, <i>i.e.</i>,
$$
\exists\ell\in{\mathbb R}~~\forall \epsilon&gt;0~~\exists \delta&gt;0~~\forall x\in(a-\delta,a)~~|F(x)-\ell|\leq\epsilon.
$$
Consider the set $A=\{F(x)~:~x &lt; a\}.$ Then $A\neq\phi$
and bounded from above (by $F(a)$). 
<p></p>
So $\sup(A)\in{\mathbb R}.$
<p></p>
Choose $\ell = \sup(A).$
<p></p>
Take any $\epsilon&gt;0.$
<p></p>
Then $\exists y &lt; a~~F(y) &gt; \ell-\epsilon.$ 
<p></p>
Choose $\delta = a-y &gt; 0.$
<p></p>
Take any $x\in(a-\delta,a) = (y,a).$
<p></p>
Then $F(y)\leq F(x) \leq \ell,$ or, in other words, $\ell-\epsilon\leq F(x)\leq \ell.$
<p></p>
So $|F(x)-\ell|\leq \epsilon,$ as required.
<b><i>[QED]</i></b>
</p>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let $X$ have CDF $F.$ Then 
$$
\forall a\in{\mathbb R}~~F(a-) = P(X &lt; a).
$$
</fieldset>

<p>
<b><i>Proof:</i></b>
Take any $a\in{\mathbb R}.$
<p></p>
Let $A = \{X &lt; a\}$ and let $A_n
= \left\{X \leq a-\frac 1n\right\}$ for $n\in{\mathbb N}.$
<p></p>
Then $A_n\nearrow A.$
<p></p>
Hence $P(A_n)\rightarrow P(A).$
<p></p>
So $F\left(a-\frac 1n\right)\rightarrow P(A).$
<p></p>
But $F\left(a-\frac 1n\right)\rightarrow F(a-),$ since $F(a-)$ exists.
<p></p>
Hence $P(X &lt; a) = F(a-),$ as required.
<b><i>[QED]</i></b>
</p>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let $X$ have CDF $F.$ Then 
$$
\forall a\in{\mathbb R}~~P(X=a) = F(a)-F(a-).
$$
</fieldset>

<p>
<b><i>Proof:</i></b>
$P(X=a) = P(X\leq a)-P(X &lt; a).$
<b><i>[QED]</i></b>
</p>

<p></p>

<h2><a
name="Different types of random variables">Different types of random variables</a></h2>
Depending on the distribution, a random variable may be of 3
types:
<ul>

<li>
<b>Discrete:</b> These random variables take only countably
many (finite/infinitely many) values.</li>

<li>
<b>Continuous:</b> If a random variable takes values in some
set $S$ such that $\forall a\in S~~P(X=a)=0,$ then we
call it a continuous random variable. Notice that
a continuous
random variable is not defined as a random variable that takes a
"continuous stretch of values". However, most continuous random
variables in practice do indeed take all values in an interval, <i>e.g.</i>, height
of a randomly selected person.</li>

<li>
<b>Neither discrete nor continuous:</b> These take
uncountably many values and for at least one value $a$ we
have $P(X=a)&gt;0.$ </li>

</ul>
The following theorem justifies the adjective "continuous" for a
random variable.
<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
A random variable is continuous if and only if its CDF is
continuous everywhere.
</fieldset>

<p>
<b><i>Proof:</i></b>
Obvious from the last theorem.
<b><i>[QED]</i></b>
</p>
In this course we shall focus on discrete random variables only.
<p></p>

<p></p>
The distribution of a discrete random variable is completely
specified by the countable set of values it can take, and the
probability with which it takes each of those values. These two
specifications together are called the <b>probability mass
function (PMF)</b> of the rv. 
<p></p>

<h1><a
name="PMF">PMF</a></h1>

<p></p>

<fieldset>
<legend><b>Definition: Probability Mass Function (PMF)</b></legend>
Let $X$ be a discrete random variable taking
values $x_1,x_2,...$ with
probabilities $p_1,p_2,...$. Then the <b>probability mass
function (PMF)</b> of $X$ is defined as $p:{\mathbb R}\rightarrow[0,1]$ where 
$$
p(x) = \left\{\begin{array}{ll}p_i&\text{if }x=x_i\\0&\text{otherwise.}\end{array}\right..
$$
</fieldset>
Clearly, $\sum p_i = 1$ and $\forall i~~p_i\geq 0.$ A
consequence of the fundamental theorem of probability is that for
any countable set $\{x_1,x_2,...\}$ and for any
sequence $(p_i)_i,$ for which $\forall i~~p_i\geq 0$
and $\sum p_i=1,$ there is a (discrete) random variable of
which the PMF is $p(x)$  given above.
<p></p>
The CDF of a discrete random variable is a step function like the one we saw in our example.
<p></p>

<h1><a
name="Expectation of a random variable">Expectation of a random variable</a></h1>

<p></p>
For many random variables we see a striking example of
statistical regularity. As an example, consider this gambling game: 
<blockquote>A fair die is rolled. If it shows an odd number then I pay you Rs 20, else you pay me Rs 10.</blockquote>
A typical plot of my running average gain per game against number of games is as follows:
<center>
<table width="100%">
<tr>
<th><img width="" src="image/explotnow.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
It is produced by the following code. 
<font color="red">
<pre>
w = sample(6,1000,rep=T)
profit =c(-20,10,-20,10,-20,10)
X = profit[w]
avgX = cumsum(X)/(1:1000)
#png('image/explotnow.png')
plot(avgX,ty='l',xlab="#games played",ylab="My running avg gain")
#dev.off()
</pre>
</font><input type="button"
value="Run in cloud"
onclick="javascript:aha(encodeURI(`
w = sample(6,1000,rep=T)
profit =c(-20,10,-20,10,-20,10)
X = profit[w]
avgX = cumsum(X)/(1:1000)
#png('image/explotnow.png')
plot(avgX,ty='l',xlab="#games played",ylab="My running avg gain")
#dev.off()
`));"/>
In fact, it is this phenomenon that first let man to study
probability. If you run a gambling game a large number of time
the running average profit per game becomes more and more stable. Gamblers wanted
to guess this stable value beforehand. They argued as follows:
<blockquote>
If I play this game a large number of times (say $n$ times),
then
approximately $\frac n2$ times I should get $10$
and the remaining $\frac n2$ times I should get $-20.$ So
approximately my total gain would be
$$
\frac n2\times 10 + \frac n2\times (-20).
$$
So the average should be approximately this divided by $n,$
<i>i.e.</i>,
$$
\frac 12\times 10 + \frac 12\times (-20) = -5.
$$
</blockquote>
Indeed, this simple argument turns out to be remarkably
accurate. Gamblers could not understand why it becomes so
accurate as $n$ becomes large. But nevertheless they used this formula to
find out what they could expect the random variable to do in the
long run.
<p></p>

<h2><a
name="Finite case">Finite case</a></h2>

<p></p>

<fieldset>
<legend><b>Definition: Expectation (finite case)</b></legend>
Let a random variable $X$ take only finitely many
values $x_1,x_2,...,x_k$ with
probabilities $p_1,p_2,..., p_k$.
Then we define the <b><font color="red" size="40">expectation</font></b> of $X$ as
$$
E(X) = \sum_1^k p_i x_i.
$$
</fieldset>

<p></p>
::<p>
<b>EXERCISE 1:</b>&nbsp;A random variable $X$  takes the values $-2, -1, 0, 1 $  and $2$  with
 probabilities $p,q,1-2p-2q, p$  and $q,$  respectively. Find $E(X).$</p>

<p></p>
::<p>
<b>EXERCISE 2:</b>&nbsp;A random variable takes the values $1,2,...,10$  with probabilities
 $p_1,p_2,...,p_{10},$  respectively, where $\sum_i p_i = 1.$  Prove that $1\leq
 E(X)\leq 10.$  Also find $p_i$'s if $E(X) = 10.$  </p>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>Let $X$  and $Y$  be random variables taking only finitely many values, and  $X\leq
 Y.$  Then  $E(X)\leq E(Y).$  </fieldset>

<p>
<b><i>Proof:</i></b>
Here $X\leq Y$  means $\forall \omega\in\Omega~~X(\omega)\leq Y(\omega).$
<p></p>
Let $X$ take values $x_1,...,x_m,$  and $Y$  take values $y_1,...,y_n.$
<p></p>
Let $p_{ij} = P(X=x_i, Y=y_j).$  
<p></p>
Clearly, if $p_{ij}&gt;0,$  then we must have $x_i\leq y_j.$  
<p></p>
Now 
$$\begin{eqnarray*}E(X) &amp; = &amp; \sum_i x_i P(X=x_i) = \sum_i (x_i \sum_j p_{ij}) =\sum_i\sum_j (x_i p_{ij})\\
&amp; \leq &amp;  \sum_i\sum_j (y_j p_{ij}) ~~[\because p_{ij}&gt;0\Rightarrow x_i\leq y_j]\\
&amp; = &amp;  \sum_j\sum_i (y_j p_{ij})[\because \mbox{addition is associative and commutative}]\\
&amp; = &amp; \sum_j (y_j \sum_i p_{ij}) = \sum_j y_j P(Y=y_j) = E(Y).
\end{eqnarray*}$$
<b><i>[QED]</i></b>
</p>

<p></p>
So far we have defined expectation for only  random variables that take finitely many values. 
We shall call such random variables <b><font color="red" size="40">simple</font></b>.
However, not all random variables are simple. We shall now generalise 
the definition of expectation for those cases as well. The generalisation turns out to be slightly tricky. 
So read this part very carefully. 
<p></p>

<h2><a
name="Nonnegative case">Nonnegative case</a></h2>
First, we shall consider a random variable, $X$, taking only nonnegative values. Now consider
 a simple random variable $U$  such that $U\leq X.$ 
Visualise $X$  and $U$  like this (we are taking $\Omega$  an interval in the diagram):   
<center>
<table width="100%">
<tr>
<th><img width="" src="image/lebmot1.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
 Then we can compute $E(U).$  Also     it is natural to
 define $E(X)$  so that $E(U)\leq E(X).$ 
<p></p>
Now look at $U$  taken as follows. 
<center>
<table width="100%">
<tr>
<th><img width="" src="image/lebmot2.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
This $U$  still takes finitely many values, but is much closer to $X $ than before. You can feel that if $U$ 
 is made finer and finer (but still remaining simple), you can make it come arbitrarily closer to $X.$
 This leads to the following approach for defining expectation of $X:$
<blockquote>Define $E(X)$  as supremum of $\{E(U)~:~U\mbox{ simple, }U\leq X\}.$  </blockquote>
Of course, before we can take supremum we need to make sure that the set is non-empty and bounded. 
<ul>
<li>It is easy to see that the set is non-empty (<i>i.e.</i>, for all nonnegative random variable $X$, there is at
 least one simple random variable $U$  such that $U\leq X.$  Just take $U\equiv 0.$  </li>

<li>Unfortunately, the set need not be bounded above. But that is not a serious problem. We shall
 just define $E(X)$  to be $\infty$  in those cases.</li>

</ul>

<fieldset>
<legend><b>Definition: Expectation (nonnegative case)</b></legend>
Let $X$  be any nonnegative random variable.
Then we define the <b><font color="red" size="40">expectation</font></b> of $X$ as
$$
E(X) = \sup\{E(U)~:~U\mbox{ simple, }U\leq X\}
$$
if the set is bounded above, and $\infty$  otherwise.
</fieldset>

<p></p>
::<p>
<b>EXERCISE 3:</b>&nbsp;Suppose $X$  is a nonnegative
 random variable that is also a simple random variable. Then we have two definitions of
 $E(X),$  as a simple random variable and as a non-empty random variable. Show that both
 definitions match in this case.</p> 

<p></p>

<h2><a
name="General case">General case</a></h2>
Finally, we attack the general case, where $X $ can take both positive and negative values. 
Here we apply our approach to the positive and the negative parts separately.  More precisely, we define 
$$X_+ = \max\{X,0\} \mbox{ and } X_- = \max\{-X,0\}.$$
Note that
<ul>
<li>Both $X_+$  and $X_-$  are nonnegative,</li>

<li>$X = X_+-X_-.$</li>

</ul>
We already know how to define $E(X_+)$ and $E(X_-).$  We shall combine them in the obvious way to define $E(X):$
<fieldset>
<legend><b>Definition: Expectation (general case)</b></legend>
$$E(X) = \left\{\begin{array}{ll}
E(X_+)-E(X_-)&\text{if }E(X_+),E(X_-)&lt;\infty\\
\infty&\text{if }E(X_+)=\infty,~E(X_-)&lt;\infty\\
-\infty&\text{if }E(X_+)&lt;\infty,~E(X_-)=\infty\\
\end{array}\right..$$
We shall say $E(X)$  is undefined if $E(X_+)=E(X_-)=\infty.$
</fieldset>

<p></p>
::<p>
<b>EXERCISE 4:</b>&nbsp;If $X$  is a nonnegative random variable, then we have two definitions for $E(X).$ 
 Check that they match.</p>

<p></p>
This expectation is also called the <b><font color="red" size="40">Lebesgue integral</font></b>  of $X$  <b><font color="red" size="40">wrt</font></b>  the given probability,
 and written as $\int X\, dP.$  However, we shall not use this notation here. 
<p></p>

<h1><a
name="How to compute expectation easily?">How to compute expectation easily?</a></h1>
The general definition is not easy to use for computing expectation numerically, except when the random variable is simple.
 Here we discuss a few other cases where we have alternative (though equivalent) formulae for computing expectation. 
<h2><a
name="Random variables taking countably many values">Random variables taking countably many values</a></h2>

<fieldset>
<legend><b><i>Theorem</i></b></legend>If $X$  takes the nonnegative values $x_1&lt;x_2&lt;\cdots$   with probabilities
 $p_1,p_2,...$  where $\sum p_i = 1,$  then 
$$E(X) = \sum p_i x_i.$$
</fieldset>

<p>
<b><i>Proof:</i></b>
To show 
$$\sum p_i x_i = \sup\{E(U)~:~U\mbox{ simple, }U\leq X\}.$$
Let $L= \sum_i p_i x_i,$  and ${\mathcal D}=\{E(U)~:~U\mbox{ simple, }U\leq X\}.$
<p></p>
This requires showing two things: 
<ul>
<li>$L$  is an upper bound of ${\mathcal D},$</li>

<li>no number less than $L$  is an upper bound of ${\mathcal D}.$</li>
</ul>

<p></p>

<b>Step 1:</b>  To show
<p></p>
$$\forall U\in{\mathcal D}~~E(U)\leq L.$$
<p></p>
Take any  $U\in{\mathcal D}$  be any simple random variable. 
<p></p>
Let $U$  take only the values $u_1,...,u_k.$  
<p></p>
Let $p_{ij} = P(X=x_i, U=u_j).$
<p></p>
Then $E(U) =\sum_j (u_j \sum_i p_{ij}) = \sum_j\sum_i u_j p_{ij}.$  
<p></p>
Also $L = \sum_i x_i \sum_j
 p_{ij}=\sum_i  \sum_j x_i p_{ij}=\sum_j \sum_i x_i p_{ij}.$
<a href="javascript:hideShow('pf');">[Why?]</a>
<div id="pf" style="display:none;background-color:#ffcccc;">
A finite sum can always be interchanged with an infinite sum, when the summands are all nonnegative. For example,
$$\sum (a_n+b_n) = \sum a_n + \sum b_n.$$
If we write $c_{1,n}=a_n$  and $ c_{2,n}=b_n$  then this is 
$$\sum_n \sum_i c_{i,n} = \sum_i \sum_n c_{i,n}.$$  
</div>
Now $p_{ij}&gt;0\Rightarrow u_j\leq x_i.$  
<p></p>
Hence $\sum_i   u_j p_{ij}\leq \sum_i   x_i p_{ij},$  and so $\sum_j\sum_i   u_j p_{ij}\leq \sum_j\sum_i   x_i p_{ij}.$
<p></p>
Thus, $E(U)\leq L,$  as required.
<p></p>

<b>Step 2:</b>  Shall show that no $L'&lt; L$  is an upper bound of ${\mathcal D},$  <i>i.e.</i>,
<p></p>
$$\forall L'&lt; L~~\exists U\in{\mathcal D}~~E(U)&gt; L'.$$  
<p></p>
Let $U_n$  be the random variable 
$$
U_n =\left\{\begin{array}{ll}X&\text{if }X=x_1,...,x_n\\ 0&\text{otherwise.}\end{array}\right..
$$  
Then $U_n$  is a simple random variable such that $U_n\leq X.$ 
<p></p>
So $U_n\in{\mathcal D}.$
<p></p>
Also $E(U_n)
 =\sum_{i=1}^n p_i x_i\rightarrow L.$  
<p></p>
Hence $\exists N\in{\mathbb N}~~E(U_N) &gt; L'.$  
<p></p>
Choose this $U_N$  as our $U\in{\mathcal D}.$
<p></p>
Since $E(U) &gt; L',$ this completes the proof.
 <b><i>[QED]</i></b>
</p>

<p></p>
::<p>
<b>EXERCISE 5:</b>&nbsp;If $X$  takes the  values $x_1,x_2,...$  (not necessarily all nonnegative) with probabilities
 $p_1,p_2,...$  where $\sum p_i = 1$ and $\sum |p_i x_i|&lt;\infty,$ then 
$$E(X) = \sum p_i x_i.$$
</p>
::<p>
<b>EXERCISE 6:</b>&nbsp;If $X$  takes the  values $x_1,x_2,...$  (not necessarily all nonnegative) with probabilities
 $p_1,p_2,...$  where $\sum p_i = 1$ and $\sum |p_i x_i|=\infty,$ then what are the possibilities for $E(X):$ 
 finite, $\infty$, $-\infty$  or undefined? Give one example of each of the possibilities. Prove the impossibility
 of the other(s).
</p>

<p></p>

<h2><a
name="Expectation of a function">Expectation of a function</a></h2>

<p>
<b>EXAMPLE 5:</b>&nbsp;
Suppose I have a random variable that takes values $-1,0$ and $1$
with probabilities $0.1, 0.5$ and $0.4,$ respectively.
What is $E(X^2)?$
<p></p>
<b>SOLUTION:</b>
Here $X^2$ is a new random variable. Call it $Y,$ say. Then $Y$
takes values $0$ and $1$ with probabilities $0.5$
each.
<p></p>

<p></p>
So $E(Y) = \frac 12.$
 ■
</p>

<p></p>
Here is another technique to arrive at the same result. 
$$
E(X^2) = 0.1\times (-1)^2 + 0.5\times 0^2 + 0.4\times 1^2 = 0.5.
$$
This technique is often easier because here we do not need to
find the distribution of $Y=X^2$ first. Both these
techniques will always give the same answer. 
<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let a (discrete) random variable $X$ take
values $x_1,x_2,...$ with
probabilities $p_1,p_2,...$. Let $h(\cdot)$ be any
function defined on the set $\{x_1,x_2,...\}.$ If $\sum |p_i h(x_i)|
&lt;\infty,$ then we must have 
$$
E(h(X)) = \sum p_i h(x_i).
$$
Also, if $\sum|p_i h(x_i)|=\infty$ and all but finitely many
$h(x_i)$'s are $&gt;0$ (resp, $&lt;0$),
then $E(h(X))=\infty $(resp, $-\infty$).
</fieldset>

<p>
<b><i>Proof:</i></b>
If $X$ takes only finitely many values, then the result
follows from distributivity of multiplication over addition. 
<p></p>
If $X $ takes countably infinitely many values, and $h(X)$  is non-negative, then define 
$$
U_n =\left\{\begin{array}{ll}h(X)&\text{if }X=x_1,...,x_n\\ 0&\text{otherwise.}\end{array}\right.
$$  
and proceed as for the proof of $E(X)=\sum p_i x_i.$ 
<b><i>[QED]</i></b>
</p>

<p></p>

<h1><a
name="Properties of expectation">Properties of expectation</a></h1>

<h2><a
name="Relation of $E(X)$ with values of $X$">Relation of $E(X)$ with values of $X$</a></h2>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
If $X$ is a degenerate rv (<i>i.e.</i>, takes only one value with
probability 1), then $E(X)$ equals that value.
</fieldset>

<p>
<b><i>Proof:</i></b>Easy.<b><i>[QED]</i></b>
</p>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let $X, Y$ be any two random variables (defined on the same probability space) with $X\leq Y.$
If $E(X)$  and $E(Y)$  are both defined (may be $\infty$  or $-\infty$), then
$E(X)\leq E(Y).$
</fieldset>

<p>
<b><i>Proof:</i></b>
The result is trivial if $E(Y)=\infty.$  So we shall focus on the $E(Y)&lt;\infty$  case. 
<p></p>
We had defined expectation in three steps: simple, nonnegative and general. Our proof will accordingly have three steps.
<p></p>

<b>Step 1: Simple:</b>

<p></p>
We have already seen this earlier in this page.
<p></p>

<b>Step 2: Nonnegative:</b>

<p></p>
To show $E(X)\leq E(Y),$  <i>i.e.</i>, 
$$\sup\{E(U)~:~U \mbox{ simple}, U\leq X\} \leq \sup\{E(V)~:~V \mbox{ simple}, V\leq Y\}.$$
Enough to show that  $\{E(U)~:~U \mbox{ simple}, U\leq X\}\subseteq \{E(V)~:~V \mbox{ simple}, V\leq Y\}.$
<p></p>
Take any  simple $U\leq X.$  Then, since $X\leq Y,$  we also have $U\leq Y.$  Hence the result.
<p></p>

<b>Step 3: General:</b>

<p></p>
Let $X = X_+-X_-$
 and $Y = Y_+-Y_-$. 
<p></p>
Since $X\leq Y,$  we must have $X_+\leq Y_+$  and $Y_-\leq X_-.$  
<p></p>
Hence, by step 2, $E(X_+)\leq E(Y_+)$  and $E(Y_-)\leq E(X_-).$  
<p></p>
So $E(X_+)-E(X_-)\leq E(Y_+)-E(Y_-),$  as required.
<b><i>[QED]</i></b>
</p>
An immediate consequence of the above theorems is the following
theorem.
<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
If $X$ always takes values in $[a,b],$ then $E(X)$
must exist finitely, and lie in $[a,b].$
</fieldset>

<p>
<b><i>Proof:</i></b>
Easy.
<b><i>[QED]</i></b>
</p>
The condition "$X$ always lies in $[a,b]$" may be
written as $P(X\in[a,b])=1.$
<p></p>

By the way, if $X$ can take values $x_1,x_2,...$, there
is no guaranty that $E(X)$ will equal any of
the $x_i$'s. For example, if  $X$ is the outcome of
a fair die, then $E(X)=3.5,$ which is not a possible
outcome.
<p></p>

<h2><a
name="Transformation properties">Transformation properties</a></h2>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let $X$ be a discrete rv such that $E(X)$ is defined. If $a,b$ are constants, then $E(a+bX) = a+bE(X).$
</fieldset>

<p>
<b><i>Proof:</i></b>
Do it yourself. Hint: Here also you need to proceed in three steps: simple, nonnegative, general.
<b><i>[QED]</i></b>
</p>

<p></p>
::<p>
<b>EXERCISE 7:</b>&nbsp;
If $E(X) = \mu,$ then what is $E(X-\mu)?$
</p>

<p></p>

<fieldset>
<legend><b><i>Theorem</i></b></legend>
Let $X,Y$ be two random variables both defined on the same probability space.
We assume that both $E(X)$ and $E(Y)$ both exist finitely.
<p></p>
Then $E(X+Y)$ also exists finitely and we have
$$
E(X+Y) = E(X)+ E(Y).
$$
</fieldset>

<p>
<b><i>Proof:</i></b>
Another three step proof. The first and third steps are pretty easy. The second step is tricky. 
We shall give the details  next semester. But here are the main substeps for the the second step:
<ul>
<li>
<b>Substep 1:</b>  We can show that for any non-negative random variable, $Z$, we have an non-decreasing 
 sequence of simple random variables $(W_n)$  such that $W_n\nearrow Z.$</li>

<li>
<b>Substep 2:</b>  We can show that if we have any sequence $(W_n)$  and any nonnegative random
 variable $Z$  with $W_n\nearrow Z$, then $E(W_n)\rightarrow Z.$</li>

<li>
<b>Substep 3:</b>  We apply the above two substeps to both $X$  and $Y$  to obtains
 non-decreasing sequences $(U_n)$  and $(V_n)$  such that $E(U_n)\rightarrow E(X)$  and
 $E(V_n)\rightarrow E(Y).$  Since $U_n+V_n\nearrow X+Y$, the result follows from the simple case.</li>

</ul> 

<b><i>[QED]</i></b>
</p>

<p></p>
Next we shall need a new concept, that of a convex
function. Graphically, $f(x)$ is a convex function if its
graph is like a bowl opening upwards (possibly slanted). Some
examples are shown below.
<center>
<table width="100%">
<tr>
<th><img width="" src="image/convexex.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
Mathematically we may define a convex function as follows.
<table align="right" width="20%" border="1">
<tr>
<td bgcolor="pink">While this definition is graphically quite intuitive, you
may have seen other definitions of convexity
elsewhere. Read <a href="convex.html">here</a> to learn more
about equivalences between different definitions of convexity.</td>
</tr>
</table>

<fieldset>
<legend><b>Definition: Convex function</b></legend>
A function $f:{\mathbb R}\rightarrow{\mathbb R}$ is called <b>convex</b>
if $\forall a\in{\mathbb R}$ there is a line $y = \ell_a(x)$
through $(a,f(a))$ that lies on or below the graph
of $f(x),$ <i>i.e.</i>, 
$$
\forall x\in{\mathbb R}~~ \ell_a(x) \leq f(x).
$$
</fieldset>
In the following diagram the blue line is $\ell_a.$ Both the
red lines are candidates for $\ell_b.$
<center>
<table width="100%">
<tr>
<th><img width="" src="image/suppline.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<fieldset>
<legend><b><i>Jensen's inequality</i></b></legend>
Let $X$ be a random variable and $f:{\mathbb R}\rightarrow{\mathbb R}$  be any convex function. We assume that $E(X)$ 
and $E(f(X))$ both exist finitely.  Then $f(E(X))\leq E(f(X)).$
</fieldset>

<p>
<b><i>Proof:</i></b>
Let $\mu = E(X).$ Consider $\ell_\mu(x)$ as mentioned
in the definition of convexity.
<p></p>
Since the graph of $\ell_\mu(x)$ is a straight line passing
through $(\mu,f(\mu)),$ hence it must be of the form
$$\ell_\mu(x) = f(\mu)+m(x-\mu),~~x\in{\mathbb R}.$$
So 
$$
E(f(X)) \geq E(\ell_\mu(X)) = E(f(\mu))+mE(X-\mu) = f(\mu)+0 = f(E(X)),
$$
as required.
<b><i>[QED]</i></b>
</p>

<p></p>
::<p>
<b>EXERCISE 8:</b>&nbsp;Which is larger $(E(X))^2$ or $E(X^2)?$ Assume
that both exist finitely.</p>

<p></p>

<h1><a
name="Indicator trick">Indicator trick</a></h1>
Often we have to find $E(X)$  where $X$  is the count of something, <i>e.g.</i>, number of heads in 100 tosses of coin,
 or number of times something interesting happens. If you want to find $E(X)$  directly from the definition, then you
 need to find the distribution of $X$  first, which is often difficult. In such situatons the
 <b><font color="red" size="40">indicator trick</font></b> may provide a short cut. 
<p></p>

<p>
<b>EXAMPLE 7:</b>&nbsp;We have a ring of 20 lamps. A wind blows and a random subset of lamps go out. Find
 the expected number of singleton lights (<i>i.e.</i>, lighted lamps with both neighbours off).
<center>
<table width="100%">
<tr>
<th><img width="" src="image/lamps.png"></th>
</tr>
<tr>
<th>The singletons are shown with arrowheads</th>
</tr>
</table>
</center>

<p></p>
<b>SOLUTION:</b>
Let $X$  be the number of singletons. Finding the distribution of $X$  is not very difficult, but still we shall
 demonstrate the use of the indicator trick. 
<p></p>
We shall use the arrowheads as our random variables. Let the lamps be numbered from 1 to 20. Define $L_i=1$ 
 if $i$-th lamp is on and is a singleton, and $0$  else. In other words, $L_i=1$  means we have put an
 arrow head at position
 $i.$  
<p></p>
Each $L_i$  is called an <b><font color="red" size="40">indicator variable</font></b>. 
<p></p>
Clearly $X = L_1+\cdots+L_{20}.$
<p></p>
So $E(X) = E(L_1)+\cdots+E(L_{20}) = 20 E(L_1),$  since by symmetry all the $L_i$'s have the same distribution.
<p></p>
To find $E(L_1)$  we need to find just $P(L_1=1)$, which involves only lamp 1 and its two neighbours. It should
 be clear that $P(L_1) = \frac{1}{8}.$  
<p></p>
Hence $E(X) = \frac{20}{8} = \frac 52.$  
    ■
</p>

<p></p>

<h1><a
name="Problems for practice">Problems for practice</a></h1>
::<p>
<b>EXERCISE 9:</b>&nbsp;
What is $E(X)$ if $X$ takes the
values $1,2,...,n$ with probability $\frac 1n$ each?
<p><a
href="javascript:hideShow('lab1')"><b>Hint:</b></a><div
class="ans" id="lab1">$\frac{n+1}{2}.$</div></p>

</p>
::<p>
<b>EXERCISE 10:</b>&nbsp;Show that if $X$  is a random variable taking only non-negative
integer values, then 
$$E(X) = \sum_{k=1}^\infty P(X\geq k).$$
This formula often proves useful for finding expected counts.
<p><a
href="javascript:hideShow('lab2')"><b>Hint:</b></a><div
class="ans" id="lab2">
Let $p_n = P(X=n)$  for $n=0,1,2,3,...$
Then
$$\begin{eqnarray*}
P(X\geq 1) &amp; = &amp; p_1 + p_2 + p_3+\cdots\\
P(X\geq 2) &amp; = &amp; \phantom{p_1 +} p_2 + p_3+\cdots\\
P(X\geq 1) &amp; = &amp; \phantom{p_1 + p_2 +} p_3+\cdots\\
\cdots
\end{eqnarray*}$$
Now add columnwise. Non-negative series do not change value when 
you rearrange the terms.
</div></p>

</p>
::<p>
<b>EXERCISE 11:</b>&nbsp;For a group of $n$  people find the expected number of days of the year which are
 birthdays of exactly $k$  people. (Assume 365 days and that all arrangements are equally
 probable.) Also find the expected number of multiple birthdays. How large should $n$  be to
 make this expectation exceed 1?
<p><a
href="javascript:hideShow('lab3')"><b>Hint:</b></a><div
class="ans" id="lab3"> 
Let $X_i = \left\{\begin{array}{ll}1&\text{if }\mbox{exactly $k$ people have birthdays on day} i\\ 0&\text{otherwise.}\end{array}\right..$
<p></p>
Then $X = \sum_1^{365} X_i.$  
<p></p>
So $E(X) = \sum_1^{365} E(X_i).$
<p></p>
Expected number of days of the year which are  birthdays of exactly $k$  people is $\binom{n}{k}\frac{364^{n-k}}{365^{n-1}}.$
<p></p>
Expected number of multiple birthdays is $365\left\{1-\left(\frac{364}{365}\right)^n - \frac{n\times 364^{n-1}}{365^n}\right\}.$
<p></p>
[Corrected a typo thanks to Ahan Mukherjee.]
</div></p>

</p>
::<p>
<b>EXERCISE 12:</b>&nbsp;A man with $n$  keys wants to open a door (where exactly one key works). He tries the
 keys independently at random. Find the expected number of trials needed to open the door if 
 keys are tried (a) with replacement (b) without replacement.
<p><a
href="javascript:hideShow('lab4')"><b>Hint:</b></a><div
class="ans" id="lab4">(a) $\sum_1^ \infty k\cdot \left(1-\frac 1n\right)^{k-1}\cdot\frac 1n = \cdots = n.$ 
<p></p>
 (b) $\sum_1^n \frac kn = \frac{n+1}{2}.$</div></p>

</p>
::<p>
<b>EXERCISE 13:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv1.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab5')"><b>Hint:</b></a><div
class="ans" id="lab5">
$P(X=i) = \frac{^5P_{i-1}\times 5\times (10-i)!}{10!}$  for $i=1,2,3,4,5,6.$  The probability is
 0 for $i=7,8,9,10.$
</div></p>

</p>
::<p>
<b>EXERCISE 14:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv2.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab6')"><b>Hint:</b></a><div
class="ans" id="lab6">If $n$  is even, then all even values between $0$  and $n.$  If $n$  is
 odd, then all the odd values in the same range.</div></p>

</p>
::<p>
<b>EXERCISE 15:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv3.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab7')"><b>Hint:</b></a><div
class="ans" id="lab7">
(a) <center>
<table width="100%">
<tr>
<th><img width="" src="image/cdf.png"></th>
</tr>
<tr>
<th>Plot of CDF</th>
</tr>
</table>
</center>

<p></p>
(b) $P\left(X &gt; \frac 12 \right) = 1-F\left(\frac 12\right) = \frac 34.$
<p></p>
(c) $P(2&lt; X \leq 4) = F(4)-F(2) = \frac{1}{12}.$
<p></p>
(d) $P(X &lt; 3) = F(3-) = \frac{11}{12}.$
<p></p>
(e) $P(X=1) = F(1)-F(1-) = \frac 16.$
</div></p>

</p>
::<p>
<b>EXERCISE 16:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv4.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab8')"><b>Hint:</b></a><div
class="ans" id="lab8">$P(X=1) = P(X\leq 1)-P(X&lt; 1).$
<p></p>
Now $\{X &lt; 1\} = \lim_n \left\{X\leq 1-\frac 1n\right\}.$  Since this is an increasing limit, hence by continuity of 
probability, we have $P(X&lt;1) = \lim_n P\left(X\leq 1-\frac 1n\right) = \lim_n F\left(1-\frac 1n\right) = F(1-).$
<p></p>
Hence $P(X=1) = F(1)-F(1-).$
</div></p>

</p>
::<p>
<b>EXERCISE 17:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv5.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab9')"><b>Hint:</b></a><div
class="ans" id="lab9">
Here $p$  is he says, and $p^*$  is what he believes. The meteorologist is not an honest one, and may 
say something different from what he believes. His only aim is to maximise the expected score. 
<p></p>
The expected score is 
$$p^*(1-(1-p)^2) + (1-p^*)(1-p^2).$$
This is to be maximised wrt $p$  (with $p^*$  fixed). 
<p></p>
Differentiate (or think of the graph) to see that the maximising value of $p$  is $p^*.$
</div></p>

</p>
::<p>
<b>EXERCISE 18:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv6.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab10')"><b>Hint:</b></a><div
class="ans" id="lab10">
Company pays the amount $A$  with probability $p.$  It pays $0$  with probability $1-p.$
<p></p>
So its expected payoff is $pA.$  
<p></p>
Suppose that it charges $B.$  Then expected profit is $B-pA.$  To keep it 10% of $A$  we need $B = (p+0.1)A.$
</div></p>

</p>
::<p>
<b>EXERCISE 19:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv7.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab11')"><b>Hint:</b></a><div
class="ans" id="lab11">
(a) $E(X)$  would be larger, because when a student is selected at random, he is more likely to come from the larger
 buses. So $E(X)$  is a weighted average of the bus sizes where the larger buses get more weight. 
<p></p>
But $E(Y)$  is the simple average of the bus sizes.
<p></p>
(b) $E(X) = \frac{40^2+33^2+25^2+50^2}{40+33+25+50}.$
<p></p>
$E(Y) = \frac{40+33+25+50}{4}.$
<p></p>
</div></p>

</p>
::<p>
<b>EXERCISE 20:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv8.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p></p>
We assume that no draw is possible. 
<p><a
href="javascript:hideShow('lab12')"><b>Hint:</b></a><div
class="ans" id="lab12">
By the pigeon hole principle, the winner will be decided by at least 2 and at most 3 games. 
So the sample space is $\{AA, BB, ABA, BAA, BAB, ABB\}.$  The probabilities are, respectively, 
$p^2, q^2, p^2q, p^2q, pq^2, pq^2,$ where $q=1-p.$
<p></p>
 If $X$  is the random variable denoting the number of
 games played, then it takes the values, respectively, $2,2,3,3,3,3.$
<p></p>
So $E(X) = 2(p^2 + q^2) + 3(2p^2q + 2pq^2)  = 2(1+pq).$
<p></p>
This is maximised when $pq = p(1-p)$  is maximised, which is when $p=\frac 12.$
</div></p>
</p>
::<p>
<b>EXERCISE 21:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv9.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
</p>
::<p>
<b>EXERCISE 22:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv11.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab13')"><b>Hint:</b></a><div
class="ans" id="lab13">
(a) Let $X_i = \left\{\begin{array}{ll}1 &\text{if }i\mbox{-th draw is white}\\ 0&\text{otherwise.}\end{array}\right.$  for $i=1,...,10.$
<p></p>
Then $E(X_i) = P(i$-th draw is white$)=\frac{17}{40}.$  
<p></p>
So $E(X) = 10\times \frac{17}{40} = \frac{17}{4}.$  
<p></p>
(b) Let $Y_i = \left\{\begin{array}{ll}1&\text{if }i\mbox{-th white ball is selected}\\ 0&\text{otherwise.}\end{array}\right.$  for $i=1,...,17.$
<p></p>
Then $E(Y_i) = P(i$-th white ball is delected$)=\frac 14.$  
<p></p>
So $E(X) = 17\times \frac 14 = \frac{17}{4}.$  
<p></p>
</div></p>

</p>
::<p>
<b>EXERCISE 23:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv12.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
<p><a
href="javascript:hideShow('lab14')"><b>Hint:</b></a><div
class="ans" id="lab14">
Let $X_i$  be as given in the hint. 
<p></p>
Let $X = $ number of intact marriages.
<p></p>
Then $X = \sum_1^{100} X_i$
<p></p>
Now $E(X_i) = \binom{198}{50}/\binom{200}{50}=\frac{150\times149}{200\times199}.$
<p></p>
So $E(X) = \frac{150\times149}{2\times199}.$
</div></p>
</p>
::<p>
<b>EXERCISE 24:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv13.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab15')"><b>Hint:</b></a><div
class="ans" id="lab15">
$E(X) = \frac 52.$
</div></p>

</p>
::<p>
<b>EXERCISE 25:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/rossrv14.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
Here we assume that $E(X)$  exists finitely. The inequality holds even if 
$E(X^2)$  is not finite (with the interpretation that $\forall a\in{\mathbb R}~~\infty \geq a$.)
<p><a
href="javascript:hideShow('lab16')"><b>Hint:</b></a><div
class="ans" id="lab16">
You may either use Jensen's inequality with the convex function $f(x)=x^2$  or the fact that $V(X)\geq 0.$
<p></p>
Equality if and only if $V(X)= 0$, <i>i.e.</i>, if $X$  is a degenerate random variable.
</div></p>

</p>

<p></p>
::<p>
<b>EXERCISE 26:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/fellrv1.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>
You may use some approximations in parts (c) and (d) of this problem. For instamce there are
 $\frac nk$  groups of $k$  patients each, even if $\frac nk$  is not an integer. You
 may also differentiate w.r.t. $k.$ 
<p><a
href="javascript:hideShow('lab17')"><b>Hint:</b></a><div
class="ans" id="lab17">(a) $1-(1-p)^k.$
<p></p>
(b) For a group of size $k$  the random variable $X$  takes the value 
$k+1$  with probability $1-(1-p)^k$  and the value $1$  with probability $(1-p)^k.$  
<p></p>
So $E(X) = (k+1)(1-(1-p)^k)+(1-p)^k = k+1-k(1-p)^k.$
<p></p>
If there are $N$  people in all, where $N = qk+r$  with $r\in\{0,...,k-1\}$, 
then this applies to each of the $q$  groups and also the reaminder group of size $r.$  
<p></p>
So the required expectation is 
 $$q(k+1-k(1-p)^k)+r+1-r(1-p)^r.$$
If $k$  divides $N$, then this is 
$$\frac Nk(k+1-k(1-p)^k) = N+\frac Nk-N(1-p)^k = N\left(1+\frac 1k-(1-p)^k\right).$$
<p></p>
(c) Enough to minimise $1+\frac 1k-(1-p)^k$  wrt $k$  for given $p.$
<p></p>
Treating $k $ as a continuous variable, the derivative is 
$$-\frac{1}{k^2}-(1-p)^k\log(1-p).$$
<p></p>
</div></p>

</p>
::<p>
<b>EXERCISE 27:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/fellrv2.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab18')"><b>Hint:</b></a><div
class="ans" id="lab18">
Here $P(X=k) = \binom{k-1}{r-1}p^rq^{k-r}$  for $k=r,r+1,...$  where $q = 1-p.$
<p></p>
So 
$$E\left(\frac rX\right) = \sum_{k=r}^\infty \binom{k-1}{r-1}p^rq^{k-r}\frac rk.$$
Ignoring the  terms free of $k$, and massaging the rest a little, the sum  reduces to 
$$\sum_{k=0}^\infty \frac{k(k-1)\cdots(k-r+2)}{k+1} q^k.$$
This may be handled by repeated term by term integration and differentiation of the power series
$$1+q+q^2+\cdots = \frac{1}{1-q}$$
for $|q|&lt;1.$
<p></p>
You may like to deal with the $r=1$  case first.
</div></p>

</p>
::<p>
<b>EXERCISE 28:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/most4.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab19')"><b>Hint:</b></a><div
class="ans" id="lab19">Let $X = $ the number of trials needed to get the first 6. 
<p></p>
Then $P(X=k) = \left(\frac 56\right)^{k-1}\frac 16$  for $k=1,2,3,....$
<p></p>
So $E(X) = \sum_{k=1}^\infty k \left(\frac 56\right)^{k-1}\frac 16.$
<p></p>
Now, we know that $\frac{1}{1-x} = 1+x+x^2+x^3+\cdots$
if $|x|&lt;1.$  This may be differentiated term by term (needs a justification that you should learn in your real analysis
 class) to give
$$\frac{1}{(1-x)^2} = 1+2x + 3x^2+\cdots.$$
Put $x=\frac 56$  to find the required expectation.
</div></p>

</p>
::<p>
<b>EXERCISE 29:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/most6.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab20')"><b>Hint:</b></a><div
class="ans" id="lab20">
Assuming the dice to be fair, the answer does not depend on the number 
the gambler bets on. 
<p></p>
Let $X$  be the loss for unit stake on 1.
Then
$$X = \left\{\begin{array}{ll}
1&\text{if }\mbox{no die shows 1}\\
-1&\text{if }\mbox{exactly 1 die shows 1}\\
-2&\text{if }\mbox{exactly 2 dice show 1}\\
-3&\text{if }\mbox{all 3 dice show 1}\\
\end{array}\right..$$
So $P(X=1) = \left(\frac 56\right)^3$, $P(X=-1) = 3\left(\frac 16\right)\left(\frac 56\right)^2$, 
$P(X=-2) =
 3\left(\frac 16\right)^2\left(\frac 56\right)$  and $P(X=-3) = \left(\frac 16\right)^3.$
<p></p>
Hence   
$$E(X) = \left(\frac 16\right)^3(5^3-3\times 5^2-6\times5-3).$$
</div></p>

</p>
::<p>
<b>EXERCISE 30:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/most14.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab21')"><b>Hint:</b></a><div
class="ans" id="lab21">
Let $T_1 = 1.$
<p></p>
Let $T_i = $  waiting time for the $i$-th new coupon after the $(i-1)$-th coupon has been encountered, for
 $i=2,3,4,5.$
<p></p>
Consider the following example to understand the definition of $T_i$'s. Suppose that the coupons arive in the order:
<blockquote> 
<font color="#ff0000">3</font> 3 <font color="#ff0000">4</font> 3 <font color="#ff0000">5</font> 4 3 4 <font color="#ff0000">2</font> 3 4 5 <font color="#ff0000">1</font>.</blockquote>
The first occurences of each type of coupon have been shown in red. They are at positions 
$$S_1 = 1, S_2 = 3, S_3 = 5, S_4=9\mbox{ and } S_5=13.$$
We are defining $T_i = S_i-S_{i-1}$  for $i=1,...,5$  where $S_0=0.$
<p></p>
Then the $T_i$'s are independent random variables. 
<p></p>
$T_1$  is degenerate at 1,  and for $i=2,...,5$  we have
$$P(T_i = k) = q_i^{k-1}p_i$$  for $k\in{\mathbb N}$  where $p_i = \frac{i-1}{5}$  and $q_i = 1-p_i.$
<p></p>
We can easily find $E(T_i)$'s. 
<p></p>
The answer to the problem is $E(T_1+\cdots+T_5) = 1+E(T_2)+\cdots+E(T_5).$
</div></p>

</p>
::<p>
<b>EXERCISE 31:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/most15.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab22')"><b>Hint:</b></a><div
class="ans" id="lab22">
<center>
<table width="100%">
<tr>
<th><img width="" src="image/bachmod.png"></th>
</tr>
<tr>
<th>The same person may be part of two marriageable couples.</th>
</tr>
</table>
</center>
The guys are all distinct, and so are the girls (though it is not clear from my wonderful artwork!). 
<p></p>
The diagram shows 8 <i>run</i>s, <i>i.e.</i>, stretches of same gender. A single girl or a single guy consitute the shortest possible
 run. Notice that the number of marriageable couples  is one less than the number of runs.
<p></p>
Thus, the number of arrangements with $k$  marriageable couples is
 the same as the number of arrangements with $k+1$ runs.
 Here $k$  can take any value between $1$  and 14.
<p></p>
As an example let us find $P(k=3).$  
<p></p>
The total number of arrangements is of course $15!.$
<p></p>
We need $3+1=4$  runs: either male-female-male-female or female-male-female-male. 
<p></p>

<ul>
<li>
<b>Step 1:</b> Arrange the guys: 8! ways</li>

<li>
<b>Step 2:</b> Arrange the girls: 7! ways</li>

<li>
<b>Step 3:</b> Insert a separator to split  the guys into two runs: 7 ways</li>

<li>
<b>Step 4:</b> Insert a separator to split  the girls into two runs: 6 ways</li>

<li>
<b>Step 5:</b> Mix them: 2 ways (M-F-M-F or F-M-F-M)</li>

</ul>
So 
$$P(k=3) = \frac{8!\times7!\times7\times6\times2}{15!}.$$
Find these for all possible values $k$, and then compute expectation. 
<p></p>
Or...use the indicator trick!!!
</div></p>

</p>
::<p>
<b>EXERCISE 32:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/most34.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab23')"><b>Hint:</b></a><div
class="ans" id="lab23">
Let there be $n$  workers. Let $X$  be the number of working days. 
<p></p>
Let $X_i=\left\{\begin{array}{ll}1&\text{if }i\mbox{-th day is a working day}\\ 0&\text{otherwise.}\end{array}\right..$
<p></p>
Then $X = \sum_1^{365} X_i.$
<p></p>
Now $E(X_i) = P(i$-th day is a working day$)= \left(\frac{364}{365}\right)^n.$
<p></p>
So $E(X) = 365\times \left(\frac{364}{365}\right)^n.$
<p></p>
Hence expected number of man-days is 
$365n\times \left(\frac{364}{365}\right)^n=f(n)$, say.
<p></p>
We want to maximise this wrt $n.$  
<p></p>
Now 
$$\frac{f(n+1)}{f(n)} = \frac{n+1}{n}\times \frac{364}{365}.$$
This is $&gt;/=/&lt; 1$  according as $364 &gt;/+/&lt; n.$
<p></p>
So the function is maximised at $n=364$  and $365.$
</div></p>

</p>
::<p>
<b>EXERCISE 33:</b>&nbsp;<center>
<table width="100%">
<tr>
<th><img width="" src="image/most40.png"></th>
</tr>
<tr>
<th></th>
</tr>
</table>
</center>

<p><a
href="javascript:hideShow('lab24')"><b>Hint:</b></a><div
class="ans" id="lab24">
Let $X=$ number of cards required to be turned. 
<p></p>
Then $P(X=k)=\frac{4\times {}^48P_{k-1}(52-k)!}{52!}.$
<p></p>
So
</div></p>

</p>

<p></p>

<h3>Comments</h3>
To post an anonymous comment, click on the "Name" field. This
will bring up an option saying "I'd rather post as a guest."
<p></p><!--
begin disqus code --> <div id="disqus_thread"></div>
<script>
/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/

var disqus_config = function () {
this.page.url = "https://arnabc74.github.io/prob1_2024/rv.html"; // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = "rv"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://txtbk.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
</noscript><!-- end disqus code --> 

<hr/>
<table width="100%" border="0">
<tr>
<td align="left"/>
<td align="right"/>
</tr>
</table>
<hr/></body></html>
