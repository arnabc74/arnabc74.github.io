<NOTE>
@{<E>
<M>\newcommand{\ev}{{\mathcal F}}</M>
<HEAD1>First taste of measure theory</HEAD1>
If we keep on tossing a coin again and again, we are bound to get head sometime or other (assuming that <M>P(H)>0</M>). 
A proof of this may be given like this:
<Q>Let <M>A_n</M>  be the event that the first <M>n</M>  tosses have all resulted in heads. Let
 <M>A</M>  be the event that we never get a head. Then clearly <M>A_n\searrow A</M>. So by
 continuity of probability we must have <M>P(A_n)\to P(A).</M>  Now <M>P(A_n) = (*([[12]])*)^n \to
 0.</M>  Hence <M>P(A)=0.</M>  Hence <M>P(A^c)=1,</M>  i.e., we are bound to get a head some time or other.</Q>
However, we must understand that in order to write <M>A_n\searrow A</M>, we need all the <M>A_n</M>'s and <M>A</M>  to be
 subsets of some common <M>\Omega.</M>  Each element of this  <M>\Omega</M>  is an infinite sequence of heads and tails.
 If you feel uncomfortable with sets of ininite sequences, just think of <M>\Omega</M>  as the set of all functions from
 <M>\nn</M>  to <M>\{H,T\}.</M>  

<THM>This <M>\Omega</M>  is uncountable.</THM>
<PF>
Let, possible, <M>\Omega</M>  be countable. Let <M>\omega_1,\omega_2,...</M>  be an enumeration of <M>\Omega.</M>   Here
 is a typical example:
<Q>
<M>\omega_1 = </M> <RED>H</RED> T H T T T H T H ...<BR/>
<M>\omega_2 = </M> H <RED>H</RED> T H H T H T H  ...<BR/>
<M>\omega_3 = </M> T T <RED>H</RED> T T T H H T  ...<BR/>
<M>\omega_4 = </M> H T T <RED>T</RED> H T T H H  ...<BR/>
<M>\omega_5 = </M> H H H H <RED>T</RED> H T H T ...<BR/>
<M>\omega_6 = </M> T H T T T <RED>H</RED> H H T  ...<BR/>
...
</Q> 
Now define <M>\omega</M>  as the sequence that flips the diagonal entries (shown in red above). 

In our example, 
<Q><M>\omega=</M>  T T T H H T ...</Q>
Clearly, this <M>\omega</M>  is distinct rom all the <M>\omega_i</M>'s (since the <M>i</M>-th entry of  <M>\omega</M>  is
 different from that of <M>\omega_i.</M>  

But this contradicts the assumption that the <M>\omega_i</M>'s constitute an enumeration of <M>\Omega.</M>
</PF>  
<COMMENT>
for(i in 1:6) cat(sample(c('H','T'),9,rep=TRUE),'\n',sep=' ')
</COMMENT>
So far in our course, we were working with countable (finite/infinite)  <M>\Omega.</M>  For these we considered a probability
 to be a mapping from <M>{\mathcal P}(\Omega)</M>  to <M>[0,1].</M>   In other words, we could defined <M>P(A)</M>  for <I>every</I> 
 <M>A\seq\Omega.</M>  Unfortunately this may fail when <M>\Omega</M>  is uncountable. Here we may have "bad" subsets of <M>\Omega</M> 
 for whcih probability cannot be defined. 

We shall discuss such an example next. 

<HEAD1>A "bad" set</HEAD1>
Let <M>\Omega</M> be the following circle (only the circumference, not the
inside). Let the circumference have length 1.
<CIMG web="vitalli1.png">A circle</CIMG>
If I pick a point "at random" from this circle, what is the
chance that it lands in the upper semicircle? The obvious answer
is <M>[[12]].</M> What is the chance that it would land in any
given quadrant? The obvious answer this time is <M>[[14]].</M>
<P/>
In fact, for any arc, the probability equals the length of the arc.
<P/>
Also, suppose that <M>A</M> is some subset of the
circle. Let us denote by <M>A+\theta</M> the subset obtained by
rotating <M>A</M> by an angle <M>\theta.</M> Which subset has the
larger probability, <M>A</M> or <M>A+\theta?</M> Since we are
picking the point "at random" without any bias for any particular
direction, hence both <M>A</M> and <M>A+\theta</M> should have
the same probability. 
<P/>
It might come as a surprise
that there is <B>no</B> probability function <M>P</M> from the power set
of <M>\Omega</M> to <M>\rr</M> that satisfies these two
conditions simultaneously, i.e.,
<UL>
<LI>for any arc <M>A</M> we must have <M>P(A)=length(A).</M></LI>
<LI>for any <M>A\seq\Omega</M> and for any <M>\theta</M> we must
have <M>P(A) = P(A+\theta).</M></LI>
</UL>
Thus, we are claiming that we cannot have a function <M>P</M>
 definied on the entire power set of <M>\Omega</M> that satisfies
 the three probability axioms as well as these two extra conditions.
<P/>

 We shall provide  a quick proof of
this here by contradiction. Let, if posible, there be such a
function <M>P.</M> We shall demonstrate a "bad" set <M>M</M> for
which <M>P(M)</M> cannot be defined, contradicting the assumption
that <M>P</M> is defined for all subsets of <M>\Omega.</M> 
<P/>
So in this scenario, we have
to leave out "bad" sets like this from <M>\ev.</M> However, 
all subsets that we shall ever need for practical pursposes are
still in <M>\ev.</M> That is why, this technical point may safely
be ignored during a first course on probability.
<P/>
Now for the proof. Let's warm up first.

<HEAD2>Warming up</HEAD2>
Imagine the circle split up into
12 equal parts like the face of the clock. 
<CIMG web="vitalli2.png">Split up into 12 arcs</CIMG>
We have grouped the arcs into 3 different groups of size 4 each
(shown by the colours red, green and blue). The grouping is done
like this: Give any colour to any arc to start with. Then start
counting clockwise and use the
same colour to every 3rd arc. Then pick an uncoloured arc and
proceed similarly with another colour, and so on. Notice that the
parts of the different colours are all identical in shape and
size. One is just a rotated version of another. So the total
length of all the parts must be the same. 
<P/>
 <CIMG web="vitalli3.png">One arc of each colour</CIMG>
Now pick any one arc of each colour. This gives you a set. Call
it <M>M.</M> Rotate <M>M</M>
by <M>90^\circ</M> clockwise. The new set is <M>M+90^\circ.</M>
Then, notice that <M>M,
M+90^\circ, M+180^\circ</M> and <M>M+270^\circ</M> are all disjoint and build up
the entire circle.
 <CIMG web="vitalli4.png">Partitioning the circle</CIMG>
Well, that's all the warm up we need! Now for the actual thing.

<HEAD2>A set without a probability</HEAD2>
We again start with the circle, whose
circumference is 1. Also, for two points <M>x,y\in
S</M>, we shall denote the (shorter) arc length between them
by <M>|xy|.</M> This will always be in <M>[0,1/2].</M>
<P/>

Pick any point on the circle, colour
it red. Also mark all points that are at a rational distance from
this point with the same colour. Now pick a point that has not
been coloured. Colour it green, and do the same thing again: mark
all points at a rational distance from it with green. Continue
like this until all the points are coloured. Of course, this will
take infinite amount of time. What we mean mathematically, is
that for each point <M>x\in S</M> we define 
<D>
A_x = \{p\in S~:~ |px|\in\qq\}.
</D>
Note the following points:
<UL>
<LI>If <M>y\in A_x</M> then <M>x\in A_y.</M> So all
the <M>A_x</M>'s are not distinct. For example, if <M>x,y</M>
are diametrically opposite each other, then <M>A_x=A_y.</M></LI>
<LI>Each <M>A_x</M> is countable, since there are only countably
many rationals.</LI>
<LI>There are uncountably many distinct <M>A_x</M>'s (since
total number of points on the circle is uncountable).</LI>
</UL>
Now pick exactly one point from each distinct <M>A_x.</M> Call the set
of all these picked points <M>M.</M>
<P/>
This is a troublesome set. I claim that you cannot define its
probability <M>P(M).</M>
<P/>

For any rational number <M>r\in [0,1)</M> we denote
by <M>M+r</M> the set <M>M</M> rotated clockwise by distance <M>r.</M>
<P/>
Then note that
<UL>
<LI>If <M>r\neq s</M> are two rational points in <M>[0,1)</M>
then <M>M+r</M> and <M>M+s</M> are disjoint.</LI>
<LI>Let <M>\{r_1,r_2,...\}</M> be a listing all rationals
in <M>[0,1).</M>
Then 
<D>
\cup_{i=1}^\infty (M+r_i)
</D>
equals the entire circle.
</LI>
</UL>
Now, let's say that <M>M</M> has <M>P(M)=\ell.</M>
Clearly, <M>\forall r\in[0,1)</M> we must have <M>P(M+r)=\ell,</M>
as well.

<P/>
Now, if <M>\ell = 0</M> then the second
condition above implies that <M>P(\Omega)</M>
is <M>0+0+\cdots = 0,</M> which is wrong, since length
of <M>P(\Omega)</M> must be 1.
<P/>
If <M>\ell>0,</M> then <M>P(\Omega)</M> becomes <M>\ell+\ell+\cdots =
\infty,</M> again a contradiction! 
<P/>
This completes the proof
<P/>

But as you can see, such "bad" sets are pretty difficult to come
across. So ignoring them will never cause any problem during our
course. 

Still, to keep our discussion general, we need to modify the defintion of probability slightly.
Hence we should learn the following terminology.

 The modification will consist of an explicit specification of the "good" sets. In other words,
 instead of taking <M>P:{\mathcal P}(\Omega)\to[0,1],</M>  we shall now take <M>P:{\mathcal
 A}\to[0,1],</M>  where <M>{\mathcal F}\seq{\mathcal P}(\Omega)</M>  is the collection of all the
 "good" subsets of <M>\Omega.</M>  What properties should these "good" subsets have? Well, since
 we are not going to manipulate the events using set theory, <M>{\mathcal F}</M>   should naturally be closed under the set
 operations: union, intersection and complementation. Since we want to use axiom 3, we actually need <M>{\mathcal F}</M> 
 be closed under <I>countable</I>  unions (and hence <I>countable</I>  intersections, by de Morgan). 
<HEAD1>Some terminology from measure theory</HEAD1>

<DEFN name="$\sigma$-algebra/$\sigma$-field">
Let <M>\Omega</M>  be any non-empty set. Then any non-empty <M>{\mathcal F}\seq{\mathcal P}(\Omega)</M> 
 that is closed under complementation and countable union (and intersection) is called a
 <TERM>$\sigma$-algebra</TERM>  or<TERM>$\sigma$-field</TERM>  over <M>\Omega.</M> 
</DEFN>

<EXM>For any non-empty <M>\Omega</M>  we have the following two <M>\sigma</M>-algbras:
 <M>\{\phi,\Omega\}</M>  and <M>{\mathcal P}(\Omega).</M>  In all our examples with countable
 <M>\Omega</M>, we were using the latter. </EXM>

<EXR>Show that any <M>\sigma</M>-algebra over <M>\Omega</M>  must contain <M>\phi</M>  and <M>\Omega.</M></EXR>

<DEFN name="Probability space">
By a <TERM>probability space</TERM>  we mean <M>(\Omega,{\mathcal F},P)</M>, where <M>\Omega</M>  is any non-empty set, <M>{\mathcal F}\seq{\mathcal P}(\Omega)</M> 
 and <M>P:{\mathcal F}\to[0,1]</M>  satisfies the three axioms of probability.
</DEFN>
The elements of <M>{\mathcal F}</M>  are called <TERM>event</TERM>s. 


Also, we want <M>{\mathcal F}</M> 
 to contain all the subsets that we care about in a given problem. So it is only naturall that we choose <M>{\mathcal F}</M> 
 differently for different problems. There are two approaches: In the first approach, we
 characterise the "bad" sets and eliminate them from <M>{\mathcal P}(\Omega).</M>  In the other approach (the more popular
 one) we list all the sets that we want to work with and consider the smallest <M>\sigma</M>-algebra containing them. 

<EXM>Find the smallest <M>\sigma</M>-algebra over <M>\Omega=\{1,2,3\}</M>  that contains <M>\{1,2\}.</M></EXM>

In many problems we work with <M>\Omega=\rr,</M>  the real line. Then it is common to include all open sets
 in our collection of  "good" sets.  So the smallest <M>\sigma</M>-algebra containing them is a very popular <M>\sigma</M>-algebra.
 It is called the <TERM>Borel <M>\sigma</M>-algebra</TERM>.

The problem of "good" and "bad" sets comes up not just in probability theory, but whenever you want to measure the size of
 a set. For instance, the circle example could as well be posed in terms of <I>length</I> of a set instead of its <I>probability</I>.
 Any way to "measure the size of a set" must follow the axioms that we stated for probability (except the <M>P(\Omega)=1</M>).

<DEFN name="Measure space">
By a <TERM>measure space</TERM>  we mean <M>(\Omega,{\mathcal F},\mu)</M>, where <M>\Omega</M>  is any non-empty set, 
<M>{\mathcal F}</M>  is any <M>\sigma</M>-algebra over <M>\Omega</M> 
 and <M>\mu:{\mathcal F}\to[0,\infty]</M>  satisfies the following axioms:
<OL><LI>
<M>\mu(\phi)=0</M>
</LI>
<LI><M>\forall A_1,A_2,...\in{\mathcal F}~~\mu(\cup A_n)=\sum\mu(A_n).</M></LI>
</OL>
</DEFN>
As you may easily see, "length", "area", "mass", "volume", "cardinality" (for finite sets) are all examples of measures.

<DISQUSE url="https://arnabc74.github.io/prob1_2024/vit.html" id="vit"/></E>@}
</NOTE>
