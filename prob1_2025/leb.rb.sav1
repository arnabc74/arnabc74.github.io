 @{<NOTE>
<HEAD1>Second taste of measure theory</HEAD1>
We had our first taste of measure theory when we learned about <M>\sigma</M>-algebras. Our second encounter is about to happen
 in the context of defining expectation. 

For random variable taking only finitely many values <M>x_1,...,x_k</M>  with probabilities <M>p_1,...,p_k,</M>  the expectation
 is defined to be <M>E(X) = \sum_{i=1}^k p_i x_i.</M> 

If, however, the random variable takes countably infinitely many values <M>x_1, x_2, ...</M>  with
 probabilities <M>p_1, p_2,...</M>  then naively one would expect the definition to be <M>E(X) =
 \sum_{i=1}^\infty p_i x_i.</M>  But, unfortunately, this sum  may depend on the order of the terms. To make it free of the
 order we need the rather technical condition <M>\sum_{i=1}^\infty |p_i x_i|<\infty.</M>  

Moving from finite sample space to countably infinite sample space added this much complexity. Still it is not clear how
 to define it for uncountable sample space. 

A little measure theory will simplify our life a lot here, and provide one single unified
 intuitive definition of expectation that
 works everywhere. Here again we start with random variables taking only finitely many values. (We call them <TERM>simple</TERM> 
 random variables). Here we already have our intuitive definition of expectation:
<D>E(X) = \sum_{i=1}^k x_i P(X=x_i).</D>
For any nonnegative random variable <M>X</M>  we consider all simple random variables that are
 <M>\leq X.</M>  We compute the expectation of each of these, and define <M>E(X)</M>  to be their
 supremum (which may be infinite).   

For a random variable, <M>X</M>, that can take negative values as well, we define 
<D>X^+ = <CASES>X<IF>x\geq 0</IF> 0<ELSE/></CASES></D>
and 
<D>X^- = <CASES>-X<IF>x< 0</IF> 0<ELSE/></CASES>.</D>
Then <M>X = X^+-X^-,</M>  and both <M>X^+</M>  and <M>X^_</M>  are nonnegative random variables. We define
<D>E(X) = E(X^+)-E(X^-)</D>
unless we have an <M>\infty-\infty</M>  situation, in whch case we say <M>E(X)</M>  is undefined. 

This definition is quite natural, and does not care about the size of the probability space. In
 fact, it works for any measure. When used for a general measure, we call it 
</NOTE>@}
