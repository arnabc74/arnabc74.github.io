<HEAD1>Monotone convergence theorem (MCT)</HEAD1>
<THM name="MCT (simple version)">
Let <M>X_n</M> 's be non-negative  random variables with <M>X_n\uparrow X</M>  for some random variable <M>X.</M>
 Then <M>E(X_n)\uparrow E(X).</M>
</THM>
<PF>
Enough to show simple random variables <M>Y_n</M>  such that <M>Y_n\uparrow X </M> and <M>Y_n\leq X_n.</M>
<BECAUSE>
We already know <M>E(Y_n)\uparrow E(X).</M>  But <M>E(X_n)</M>  is sandwiched between <M>E(Y_n)</M>  and <M>E(X).</M>
</BECAUSE>
Let <M>(Z_{n,k})_k</M>  be the simplification of <M>X_n.</M>  

Let <M>Y_n = \max\{Z_{1,n},...,Z_{n,n}\}.</M>

Then <M>Y_1\leq Y_2\leq\cdots</M>
<BECAUSE>
<MULTILINE>
Y_{n+1} & = & \max\{Z_{1,n+1},...,Z_{n+1,n+1}\}\\
& \geq & \max\{Z_{1,n+1},...,Z_{n,n+1}\}<SINCE><M>\because</M> superset cannot have smaller max</SINCE>\\
& \geq & \max\{Z_{1,n},...,Z_{n,n}\},
</MULTILINE>
by non-decreasing property of <M>Z_{n,k}</M>  w.r.t. <M>k.</M>
</BECAUSE>
Also <M>Y_n\leq X_n.</M>
<BECAUSE>
<M>Z_{k,n}\leq X_k\leq X_n.</M>
</BECAUSE>
Finally, <M>Y_n\uparrow X.</M>
<BECAUSE>
We have <M>Z_{n,k} \leq Y_k.</M>  

Taking limit as <M>k\to \infty,</M>  we have <M>X_n\leq \lim_k Y_k.</M>

Now taking limit as <M>n\to \infty,</M>  we have <M>X\leq \lim_k Y_k.</M>  

Also we have <M>Y_n\leq X_n\leq X.</M>  So <M>\lim_k Y_k\leq X.</M>  

Hence <M>\lim_k Y_k= X.</M>
</BECAUSE>
This completes the proof.
</PF>

<EXR>
If <M>(X_n)</M>  is a <I>nonincreasing</I> sequence of nonnegative random variables converging to some random variable <M>X,</M> 
 and <M>E(X_1)<\infty,</M>  then show that <M>E(X_n)\downarrow E(X).</M>  What if the assumption <M>E(X_1)<\infty</M>  is
 dropped?
</EXR>

<EXR>
Suppose that <M>X_n</M>'s are nonnegative random variables. Show that 
<D>E(\sum_1^\infty X_n) = \sum_1^\infty E(X_n).</D>
</EXR>
In the simple version we assumed that the limit of <M>(X_n)</M>  is a random variable. In particular, we assumed that for
 each <M>\omega\in\Omega</M>  the sequence <M>(X_n(\omega))</M>  converges to some real number. We may actually drop these
 assumptions. We may allow <M>(X_n(\omega))</M>  to diverge. Then the limit <M>X(\omega)</M>  is a function from <M>\Omega</M> 
 to <M>[0,\infty].</M>  One can then <I>show</I>  (not <I>assume</I>) that this <M>X</M>  is a random variable. We do this
 below.

<THM name="MCT (less simple version)">
Let <M>(X_n)</M>  be a sequence of random variables defined on <M>(\Omega,\calF,P)</M>  such that 
<D>\forall\omega\in\Omega~~0\leq X_1(\omega)\leq X_2(\omega)\leq\cdots.</D>
Let <M>X(\omega) = \sup\{ X_n(\omega)~:~n\in\nn\}</M>  (may be <M>\infty</M>). 
Then <M>X</M>  is also a random variable, and <M>E(X_n)\to E(X).</M>
</THM>
<PF>
The proof is somewhat long. But it may be split into a number of well-motivated steps.

<U>Step 1</U>: <B>Here we shall show that <M>X</M>  is a random variable.</B>

We need to show that <M>\forall B\in  \calB~~X ^{-1}(B)\in\calF.</M>

Since <M>\calB</M>  is generated by <M>\{(-\infty, t]~:~t\in\rr\},</M>  hence enough to show 
<M>\forall t\in\rr~~X ^{-1} ((-\infty,t])\in\calF,</M>  i.e., 
<D>\forall t\in\rr~~\{X\leq t\}\in\calF.</D>
But <M>\{X\leq t\} = \cap_n \{X_n\leq t\}.</M>
<BECAUSE>
<M>\because X = \sup X_n</M>, <M>\therefore (X\leq t)\iff(\forall n~~X_n\leq t). </M>
</BECAUSE>
Since <M>X_n</M>'s are random variables, hence <M>\forall n~~\{X_n\leq t\}\in\calF.</M>  

Again, since <M>\calF</M>  is closed under countable intersection, <M>\cap_n\{X_n\leq t\}\in\calF,</M>  completing step
 1.

<U>Step 2</U>: <B>Here we shall show <M>\lim_n E(X_n) \leq E(X).</M></B>


But <M>(E(X_n))</M>  being a non-decreasing sequence, <M>\lim_n E(X_n) = \sup \{E(X_n)~:~n\in\nn\}.</M>

Again, since <M>X</M>  is a random variable (which is clearly nonnegative, since
 <M>X_n</M>'s are), <M>E(X)</M> 
 exists (may be <M>\infty</M>). 

Since <M>\forall n\in\nn~~X_n\leq X,</M>  hence <M>E(X_n)\leq E(X).</M>  So <M>\sup \{E(X_n)~:~n\in\nn\}\leq E(X).</M>  

Hence <M>\lim_n E(X_n) \leq E(X).</M>

<U>Step 3</U>: Here we shall show <M>\lim_n E(X_n) \geq E(X).</M>

We know that <M>E(X) = \sup\{E(S)~:~S\in \calD\},</M>  where <M>\calD = </M>  the set of all
 non-negative simple functions "strictly below"
 <M>X.</M>

Pick any <M>S\in \calD.</M>  

Our plan is to say ''Some <M>X_n</M>   must exceed <M>S.</M> '' But since we are dealing with
 functions, we have to be careful. 

Let <M>B_n = \{\omega\in\Omega~:~X_n(\omega) > S(\omega)\}.</M>  

Then <M>E(S\ind_{B_n})\leq E(X_n\ind_{B_n})\leq E(X_n).</M>
Our plan is to take limit over <M>n</M>  and claim that <M>E(S\ind_{B_n})\uparrow E(S).</M>

Then <M>B_n\seq B_{n+1}.</M>  
<BECAUSE>
<M>\forall\omega\in\Omega~~X_n(\omega)\leq X_{n+1}(\omega).</M>
</BECAUSE> 
Also <M>\cup_n B_n =\Omega.</M>
<BECAUSE>
Clearly, <M>\cup_n B_n \seq\Omega.</M>

Take any <M>\omega\in\Omega.</M>  

Since <M>X_n(\omega)\uparrow X(\omega), </M>  and <M>S(\omega) < X(\omega),</M>  hence <M>\exists n\in\nn ~~X_n(\omega) > S(\omega).</M>

So <M>\omega\in B_n.</M>
</BECAUSE>
Hence, by continuity of probability,  <M>E(S \ind_{B_n})\uparrow E(S).</M>  
<BECAUSE>
Let <M>S = \sum_1^r c_k \ind_{A_k}.</M>

Then <M>E(S\ind_{B_n}) = \sum_1^r c_k E(\ind_{A_k}\ind_{B_n}) = \sum_1^r c_k E(\ind_{A_k\cap B_n})=\sum_1^r c_k P(A_k\cap B_n).</M>

But <M>\lim_n(A_k\cap B_n) = A_k.</M>  

Hence, by continuity of probability, <M>\lim_n P(A_k\cap B_n) = P(A_k).</M>
</BECAUSE>
So we are now able to execute our plan, taking limit over <M>n</M>  of <M>E(S\ind_{B_n})\leq E(X_n)</M>
to get <M>E(S)\leq \lim E(X_n). </M>

But since this holds for all <M>S</M>  strictly less than <M>X,</M>  hence <M>E(X)\leq \lim_n E(X_n),</M>  
completing the proof.
</PF>
<HEAD1>Fatou and DCT</HEAD1>
-------EOD-------
