 @{<NOTE>
<M>\newcommand{\v}[1]{{\mathbf #1}}</M>
<M>\newcommand{\k}[1]{\chi^2_{(#1)}}</M>
<TITLE>Multivariate normal and related distributions</TITLE>
<HEAD1>Multivariate normal</HEAD1>
Here we shall discuss the most commonly used multivariate distribution, the multivarite normal distribution. 
<DEFN name=" Multivariate normal">
Let <M>\v X = (X_1,...,X_n)'</M>  be a random vector, where  <M>X_1,...,X_n</M>  are IID
 <M>N(0,1).</M> Let <M>A_{m\times n}</M>  be any fixed matrix, and <M>\v b_{m\times1}</M>  be any
 fixed vector. Then the joint distribution of <M>\v Y=A\v X + \v b</M>  is called <M>m</M>-dimensional
 multivariate normal. 
</DEFN>
Clearly, the distribution depends on <M>A</M>  and <M>\v b.</M> However, different values of <M>A</M>  and <M>\v b</M>  may
 lead to the same multivariate normal. To explore this dependence we first consider <M>\v X,</M>  which has characteristic function 
<D>E(\exp(i\v t'\v X) = \exp(*(-[[12]]\v t'\v t)*).</D> 
So the characteristic function of <M>\v Y = A\v X + \v b</M>  is 
<D>E(\exp(i\v t'(A\v X+\v b)) =E(\exp(i((A'\v t)'\v X+\v t'\v b)) = \exp(*(-[[12]]\v t'AA'\v t+i\v t'\v b)*).</D>
This involves <M>\v b</M>  directly, but <M>A</M>  only through <M>AA'.</M>  So we parametrise
 multivariate normal by <M>\v b</M>  and <M>AA'.</M>  It will turn out that <M>E(\v Y)=\v b</M>   and <M>V(\v Y) = AA'.</M> 
 These are more commonly denoted by <M>\v \mu</M>  and <M>\Sigma,</M>  and <M>m</M>-dimensional multivariate normal with
 these parameters is denoted by <M>N_m(\v mu, \Sigma).</M>  The abbreviation MVN is also used for multivariate normal.

<HEAD2>Nonsignular and singular</HEAD2>
The density of <M>\v X</M>  is 
<D>(2\pi)^{-[[n2]]}\exp(*(-[[12]]\v x'\v x)*)\mbox{ for }\vx\in\rr^n.</D>
If <M>A</M>  is a nonsingular matrix, then the transform <M>\v X\mapsto A\v X+\v b</M>  is a bijection. So the Jacobian formula
 gives the following density for <M>\v Y = A\v X+\v b</M>
<D>(2\pi det(AA'))^{-[[n2]]}\exp(*(-[[12]]\v y'(AA') ^{-1}\v y)*)\mbox{ for }\vy\in\rr^n.</D> 
This is sometimes called a nonsingular multivariate normal to distinguish from the case where <M>A</M>  is singular, where
 <M>\v Y</M>  does not admit a density. 

<EXR>Describe <M>N_1(5,0)</M>  distribution.</EXR>
<HEAD3>Properties</HEAD3>
<THM>
If <M>X_1,...,X_n</M>  are IID <M>N(\mu, \sigma^2),</M>  then  <M>\v X = (X_1,...,X_n)'\sim N_n((\mu,...,\mu)',\sigma^2 I_n).</M>
</THM>

<THM>
If <M>\v X\sim N_n(\v \mu, \Sigma)</M>  and <M>B_{m\times n}</M>  and <M>\v c_{m\times 1</M>  are fixed, then <M>B\v X+\v c\sim N_m(B\v \mu + \v c, B\Sigma B').</M>
</THM>
<PF>
Directly from definition. Just be careful that the variance matrix is <M>B\Sigma B'</M>  and not <M>B'\Sigma B.</M>
</PF>

In particular, we have the following corrolary.
<THM>
If <M>\v X = (X_1,...,X_n)'\sim N_n(\v \mu,\Sigma),</M>  then any subvector of  <M>\v X</M>  has multivariate normal distribution
 with the corresponding subsector of <M>\v \mu</M>  and principal submatrix of <M>\Sigma.</M>
</THM>

If two random variables are
independent, they must also be uncorrelated. However, the converse is not true. For multivariate normal the converse is also
 true.
<THM>If <M>\v X = (X_1,...,X_n)'\sim N_n(\v \mu,\Sigma),</M>  then <M>X_i</M>  and <M>X_j</M>  are
 independent if and only if <M>\sigma_{ij} = 0.</M></THM>
<PF>
First obtain the joint distribution of <M>(X_i,X_j)</M>  using the last theorem. Then show that characteristic function factors
 out.
</PF>


Next we shall discuss some distributions related to the normal distribution.
<HEAD1><M>\chi^2</M>  distribution</HEAD1>
If <M>X_1,...,X_n</M>  are IID <M>N(0,1)</M>  then the distribution of <M>\sum_1^n X_i^2</M>  is called <TERM>chi-square distribution wit degrees of freedom</TERM> 
 <M>n.</M>  We write 
<D>\sum_1^n X_i^2\sim \chi_{(n)}^2.</D>

<THM>
<M>\k n</M>  is the same as <M>Gamma(*([[n2]],[[12]])*).</M>
</THM>
<HEAD3><M>t</M>  distribution</HEAD3>
<HEAD3><M>F</M>  distribution</HEAD3>

<HEAD2>Sampling distributions for normal sample</HEAD2>

<HEAD1>Problems for practice</HEAD1>
<EXR>If <M>X</M>  has a density of the form <M>f(x) \propto \exp(a+b+cx^2),~~x\in\rr,</M>  then
 find <M>E(X)</M>  and <M>V(X)</M>  in terms of <M>a,b,c.</M>  Also find median of <M>X.</M></EXR>
<EXR>Construct <M>(X,Y)</M> such that marginally <M>X</M>
and <M>Y</M> have <M>N(0,1)</M> distribution, but <M>(X,Y)</M>
is not bivariate normal.</EXR>
<EXR>Suppose that you have a software to generate IID replications from <M>N(0,1).</M>  Let
<M>\mu\in\rr^n</M>  and  <M>\Sigma</M>  be any <M>n\times n</M>  PD matrix. Suggest how you can
 use the software to generate a single observation from <M>N_n(\mu,\Sigma).</M>  Assume that the
 software can perform matrix operations.</EXR>
<EXR>If <M>X,Y</M>  are IID <M>N(0,1)</M>, then what is the chance that the random point
 <M>(X,Y)</M>  lies in the annulus shown below?
<CIMG web="annulus.png"/>
Express you answer in terms CDF of some standard distribution.
</EXR>
<EXR>Let <M>X_1,...,X_n</M>  be a random sample from <M>N(\mu,\sigma^2)</M>  for some
 <M>\mu\in\rr</M>  and <M>\sigma^2>0.</M>  Find <M>a<b</M>  such that <M>P(*(a< [[\bar
 X-\mu][S/\sqrt{n}]] < b)*) = 0.95</M>  and <M>b-a</M>  is the least possible subject to this.</EXR>
<EXR><EIMG web="rossfcpnorm1.png"/></EXR>
<EXR><EIMG web="rossfcpnorm2.png"/></EXR>
<EXR><EIMG web="rossfcpnorm3.png"/></EXR>
<EXR><EIMG web="rossfcpnorm4.png"/></EXR>
<EXR><EIMG web="rossfcpnorm5.png"/></EXR>
<EXR><EIMG web="rossfcpnorm6.png"/></EXR>
<EXR><EIMG web="rossfcpnorm7.png"/></EXR>
<EXR><EIMG web="rossfcpnorm8.png"/></EXR>
<EXR><EIMG web="rossipmnorm1.png"/></EXR>
<EXR><EIMG web="rossipmnorm2.png"/></EXR>
</NOTE>@}
