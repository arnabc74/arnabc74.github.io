<NOTE>
@{<E>
<UPDT>SAT JUN 04 IST 2022</UPDT>
<HEAD1>Linear Statistical Models</HEAD1>
This is the webpage for the Linear Models course (B. Stat. (hons)
III, 2020).
<P/>
<NEWS src="news.html"/>

<P/>

<HEAD2>Video lectures and exercises</HEAD2>
<UL>
<LI><LINK to="https://youtu.be/C1UnnYzrizo">Lecture 1</LINK>:
Introduction using approximately consistent linear system of
equations. Concept of orthogonal projection presented
pictorially, normal equation.</LI>
<LI><LINK to="https://youtu.be/jxxfQ7SxLOA">Lecture 2</LINK>:
Solving the toy problem from the last video by R: lm as well as
brute force normal equations.</LI>
<LI><LINK to="https://youtu.be/c8mBKaq83-8">Lecture 3</LINK>: R
workflow using faraway package.</LI>
<LI><LINK to="https://youtu.be/KZo4o3Q_vJw">Lecture 4</LINK>:
Terminology: factor, covariate, ANOVA, regression, ANCOVA, 
           treatment, control, random error</LI>
<LI><LINK to="https://youtu.be/fzRywERTg4o">Lecture 5</LINK>: A
complete example from set up to analysis using R: springs.</LI>
<LI><LINK to="https://youtu.be/-phZYb_zrIQ">Lecture 6</LINK></LI>
<LI><LINK to="https://youtu.be/k1vq2NU6k28">Lecture 7</LINK>:
Constructing a model from a description. Details of a blackbox with two inputs (spring example). data
layout, subscripting. model. R lab.</LI>
<LI><LINK to="https://youtu.be/GTkVNDJQQ-8">Lecture 8</LINK>:
Statistical assumptions on the errors. Gauss-Markov set up.</LI>
<LI><LINK to="https://youtu.be/PHU7pfe9Y5w">Lecture 9</LINK> (19:44):
bias and variance under Gauss-Markov set up. BLUE. Gauss-Markov
theorem (full col rank version) with motivation and proof.</LI>
<LI><LINK to="https://youtu.be/3-BD8EqCAtg">Lecture 10</LINK> (24:01):
Gauss-Markov theorem (general form), identifiability, departures
from assumptions.</LI>
<LI><LINK to="https://youtu.be/Yc-EEOYnaPU">Lecture 11</LINK>
(24:02): Estimating error variance</LI>
<LI><LINK to="https://youtu.be/xaJj2TRj1LY">Lecture 12</LINK>
(32:27): 1-way ANOVA* agricultural example. R.</LI>
<LI><LINK to="https://www.youtube.com/watch?v=0aX52znHbJo&t=39s">Lecture
13</LINK>(22:49): 2-factor model (part 1), interaction chart.
</LI>
<LI><LINK to="https://www.youtube.com/watch?v=6jEwtWR3tIQ&t=251s">Lecture
14</LINK>: (29:28) Control, confounding, blocking,
randomisation, design of experiments</LI>
<LI><LINK to="https://www.youtube.com/watch?v=B3-EEmYAJK8&t=5s">Lecture
15</LINK> (12:39): 2-factor model in R</LI>
<LI><LINK to="https://www.youtube.com/watch?v=aOIx7rXKT4s">Lecture
16</LINK> (26:31): 2-factor model with interaction</LI>
<LI><ALERT/><LINK to="ex1.html">Exercise set 1</LINK></LI>
<LI><LINK to="https://youtu.be/gnLNb_iqi9o">Lecture 17</LINK>
(32:26): Goodness of fit, residuals, RSS, R-squared, , R-squared
(adj) </LI>
<LI><LINK to="https://youtu.be/WfYiBkd4onE">Lecture 18</LINK>
(): Test of hypotheses (part 1), set up through an example,
subspace of column space, pictorial representation of test</LI>
<LI><LINK to="https://youtu.be/99Y5ENGWAxU">Lecture 19</LINK>
(): Project 2</LI>
<LI><LINK to="https://youtu.be/rolgYPN_e_U">Lecture 20</LINK>
(17:01): Test of hypotheses (part 2), LRT</LI>
<LI><LINK to="https://youtu.be/Xn2epWqS-48">Lecture 21</LINK>
(22:21): Test of hypotheses (part 3), derivation of null distribution</LI>
<LI><LINK to="https://youtu.be/QlqvSEE2a2o">Lecture 22</LINK>
(14:19): Test of hypotheses (part 4) using R</LI>
<LI><LINK to="https://youtu.be/5x1s3ruRARk">Lecture 23</LINK>
(36:31): 1-way ANOVA identity, orthogonal split up of SS.</LI>
<LI><LINK to="https://youtu.be/Tm3ROwspy_A">Lecture 24</LINK> (25:48):
Multiple hypotheses testing (part 1) FDR, Bonferroni, Fisher LSD.</LI>
<LI><ALERT/><LINK to="ex2.html">Exercise set 2</LINK></LI>
<LI><LINK to="https://youtu.be/KeyPf4DLri4">Lecture 25</LINK> (8:35):
Multiple hypotheses testing (part 2), Tukey's HSD</LI>
<LI><LINK to="https://youtu.be/sU4BQgkL15k">Lecture 26</LINK> (14:10):
Model selection, AIC, BIC</LI>
<LI><LINK to="https://youtu.be/YRzxQQQ1s-c">Lecture 27</LINK> (11:45):
Multiple hypotheses testing (part 3): using R</LI>
<LI><LINK to="https://youtu.be/mT5qxWbIgn0">Lecture 28</LINK>(missing): 
Covariance structures (part 1)</LI>
<LI><LINK to="https://youtu.be/JUWQMO1317M">Lecture 29</LINK>
(15:20): Covariance structures (part 2), GLS, IRLS</LI>
<LI><LINK to="https://youtu.be/1FFaShGKK3M">Lecture 30</LINK>(17:29): 
Covariance structures (part 3): Using R</LI>
<LI><LINK to="https://youtu.be/QoOF8vdUFCo">Lecture 31</LINK>:
Influence diagnostics (part 1)</LI>
<LI><LINK to="bkw20_52.pdf">Some reference
material from Belsley, Kuh and Welsch</LINK></LI>
<LI><LINK to="https://youtu.be/t6DlcCz4V2I">Lecture 32</LINK>:
Influence diagnostics (part 2)</LI>
<LI><LINK to="https://youtu.be/07mlgpBsbWw">Lecture 33</LINK>:
Multicollinearity (part 1)</LI>
<LI><LINK to="https://youtu.be/qpMFcxcbG4Y">Lecture 34</LINK>:
Multicollinearity (part 2)</LI>
<LI>A short discussion about different formuations of
<LINK to="ridge.html">ridge regression</LINK>.</LI>
<LI><LINK to="https://youtu.be/M8jBna_VVKo">Lecture 35</LINK>:
Multicollinearity in R: Ridge regression</LI>
<LI><LINK to="https://youtu.be/WXaGLAZ-MQE">Lecture 36</LINK>:
Multicollinearity in R: Lasso and subset selection</LI>
<LI><LINK to="https://youtu.be/XtTuMtMzXzk">Lecture 37</LINK>: Linear mixed effects models (part 1)</LI>
<LI><LINK to="https://youtu.be/yT7tkG3Zyis">Lecture 38</LINK>: Linear mixed effects models (part 2)</LI>
<LI><LINK to="https://youtu.be/H81FsYMkZ2g">Lecture 39</LINK>: Linear mixed effects models (part 3)
Here is <LINK to="blup.pdf">the paper mentioned in the video</LINK>.</LI>
<LI><LINK to="https://youtu.be/zJD2bNuMP4A">Lecture 40</LINK>:
Mixed effects models in R (part 1)</LI>
<LI><LINK to="https://youtu.be/z201b9qBadM">Lecture 41</LINK>:
Mixed effects models in R (part 2)</LI>
<LI><LINK to="https://youtu.be/UupGKE6QDRw">Lecture 42</LINK>:
Linear mixed effects models (part 4)</LI>
<LI><ALERT/><LINK to="ex4.html">Exercise set 4</LINK></LI>
<LI><LINK to="https://youtu.be/-01r7JKfQWE">Lecture 43</LINK>: Generalized linear models (part 1)</LI>
<LI><LINK to="https://youtu.be/u1UY1NuSpzc">Lecture 44</LINK>: Generalized linear models (part 2)</LI>
<LI><LINK to="https://youtu.be/ZzhsuDR0eGc">Lecture 45</LINK>: Generalized linear models
(part 3): Using R</LI>
</UL>

<COMMENT>
<HEAD2>Class notes</HEAD2>
I shall be updating the class notes during the course. 
<UL>
<LI><LINK to="intro.html">Introduction</LINK></LI>
<LI><LINK to="types.html">Different types of linear
models</LINK></LI>
<LI><LINK to="anova.html">ANOVA</LINK></LI>
<LI><LINK to="linalg.html">Linear algebra</LINK></LI>
<LI><LINK to="model.html">Estimation under model assumptions</LINK></LI>
<LI><LINK to="test.html">Testing under model assumptions</LINK></LI>
<LI><LINK to="posthoc.html">Multiple comparisions</LINK></LI>
<LI><LINK to="diag.html">Diagnostics</LINK></LI>
<LI><LINK to="gls.html">Generalised least squares</LINK></LI>
<LI>Mixed linear models [<LINK to="mixed.html">page 1</LINK> | <LINK to="mixed2.html">page 2</LINK>| <LINK to="mixed3.html">page 3</LINK>]</LI>
</UL>
</COMMENT>
<HEAD2>Course assessment</HEAD2>
No midsem, Sem 70 marks. <LINK to="projects.html">Two
projects</LINK> worth 10 marks each. Assignments
worth 10 marks.

<HEAD2>Reference</HEAD2> 
The main textbook is 
<B>Linear models with R</B> by <I>Julian J. Faraway</I>. It is
written in a non-mathematical way with due emphasis on the
statistical applications. 
<P/>
A more mathematical exposition (not recommended for this course) is available in the following two
books:
 <UL>
<LI><B>Linear Models_ An Integrated Approach</B> by <I>Sreenivasa
Rao Jammalamadaka, Debasis Sengupta</I></LI>
<LI><B>Plane answers to Complex Questions</B> by <I>Ronald Christensen</I></LI>
</UL>
A rather fat book (about 1400 pages) that presents everything in
great details is 
<UL>
<LI><B>Applied Linear Statistical Models</B> by <I>Kutner,
Nachtsheim, Neter and Li.</I></LI>
</UL>


<DISQUSE id="lmindex1" url="https://arnabc74.github.io/linmod/index.html"/>
</E>@}
</NOTE>
